{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raswanth-Prasath/NGSIM-Driving-Behavior-Analysis/blob/main/NGSIM_Driving_Behavior_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pairs before validation: 966462\n",
            "Pairs after validation: 963929\n",
            "Found 2029 valid car-following pairs\n",
            "Exported 2029 car-following pairs to all_car_following_pairs.csv\n",
            "Selected 5 specific car-following pairs for analysis\n",
            "Exported 5 car-following pairs to selected_car_following_pairs.csv\n",
            "\n",
            "Pair 1:\n",
            "Leader ID: 120.0\n",
            "Follower ID: 125.0\n",
            "Duration: 28.1 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 17.80\n",
            "  std: 6.47\n",
            "  min: 10.29\n",
            "  max: 28.33\n",
            "\n",
            "speed_difference:\n",
            "  mean: 0.28\n",
            "  std: 1.40\n",
            "  min: -3.13\n",
            "  max: 3.17\n",
            "\n",
            "time_headway:\n",
            "  mean: 1.30\n",
            "  std: 0.23\n",
            "  min: 1.00\n",
            "  max: 1.78\n",
            "\n",
            "Pair 2:\n",
            "Leader ID: 1087.0\n",
            "Follower ID: 1101.0\n",
            "Duration: 20.1 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 37.24\n",
            "  std: 17.02\n",
            "  min: 17.05\n",
            "  max: 65.33\n",
            "\n",
            "speed_difference:\n",
            "  mean: 2.25\n",
            "  std: 1.86\n",
            "  min: -2.29\n",
            "  max: 5.32\n",
            "\n",
            "time_headway:\n",
            "  mean: 2.14\n",
            "  std: 0.68\n",
            "  min: 1.25\n",
            "  max: 3.24\n",
            "\n",
            "Pair 3:\n",
            "Leader ID: 2066.0\n",
            "Follower ID: 2074.0\n",
            "Duration: 22.3 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 45.91\n",
            "  std: 8.10\n",
            "  min: 35.46\n",
            "  max: 64.52\n",
            "\n",
            "speed_difference:\n",
            "  mean: -1.29\n",
            "  std: 1.64\n",
            "  min: -4.63\n",
            "  max: 1.39\n",
            "\n",
            "time_headway:\n",
            "  mean: 2.82\n",
            "  std: 0.53\n",
            "  min: 2.14\n",
            "  max: 3.71\n",
            "\n",
            "Pair 4:\n",
            "Leader ID: 260.0\n",
            "Follower ID: 267.0\n",
            "Duration: 23.3 seconds\n",
            "Lane: 2\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 25.34\n",
            "  std: 8.58\n",
            "  min: 9.60\n",
            "  max: 38.08\n",
            "\n",
            "speed_difference:\n",
            "  mean: 1.06\n",
            "  std: 1.15\n",
            "  min: -1.89\n",
            "  max: 2.69\n",
            "\n",
            "time_headway:\n",
            "  mean: 3.16\n",
            "  std: 0.61\n",
            "  min: 1.48\n",
            "  max: 4.16\n",
            "\n",
            "Pair 5:\n",
            "Leader ID: 1463.0\n",
            "Follower ID: 1478.0\n",
            "Duration: 67.0 seconds\n",
            "Lane: 3\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 21.33\n",
            "  std: 6.23\n",
            "  min: 10.32\n",
            "  max: 30.68\n",
            "\n",
            "speed_difference:\n",
            "  mean: -0.15\n",
            "  std: 1.03\n",
            "  min: -2.68\n",
            "  max: 2.62\n",
            "\n",
            "time_headway:\n",
            "  mean: 4.33\n",
            "  std: 2.71\n",
            "  min: 2.26\n",
            "  max: 18.86\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Dict, Tuple\n",
        "\n",
        "@dataclass\n",
        "class CarFollowingPair:\n",
        "    \"\"\"\n",
        "    Represents a validated car-following pair with all relevant information\n",
        "    \"\"\"\n",
        "    leader_id: int\n",
        "    follower_id: int\n",
        "    \n",
        "    start_frame: int\n",
        "    end_frame: int\n",
        "    lane_id: int\n",
        "    \n",
        "    metrics: Dict = None\n",
        "\n",
        "    @property\n",
        "    def duration(self) -> float:\n",
        "        \"\"\"Duration of car-following episode in seconds\"\"\"\n",
        "        return (self.end_frame - self.start_frame + 1) * 0.1  # Convert frames to seconds\n",
        "\n",
        "class CarFollowingIdentifier:\n",
        "    \"\"\"\n",
        "    Identifies and validates car-following pairs in trajectory data\n",
        "    \"\"\"\n",
        "    def __init__(self, min_duration: float = 20.0,\n",
        "                 min_spacing: float = 2.0,\n",
        "                 max_spacing: float = 100.0):\n",
        "        \"\"\"\n",
        "        Initialize with validation criteria\n",
        "        \n",
        "        Parameters:\n",
        "        min_duration: Minimum duration in seconds for valid car-following\n",
        "        min_spacing: Minimum allowed spacing between vehicles (meters)\n",
        "        max_spacing: Maximum allowed spacing between vehicles (meters)\n",
        "        \"\"\"\n",
        "        self.min_duration = min_duration\n",
        "        self.min_frames = int(min_duration * 10)  # Convert to frames (0.1s intervals)\n",
        "        self.min_spacing = min_spacing\n",
        "        self.max_spacing = max_spacing\n",
        "        \n",
        "    def identify_pairs(self, df: pd.DataFrame) -> List[CarFollowingPair]:\n",
        "        \"\"\"\n",
        "        Main method to identify valid car-following pairs, with integrated leader-follower validation\n",
        "        \n",
        "        Parameters:\n",
        "        df: DataFrame with columns for Vehicle_ID, Frame_ID, Lane_ID, LocalY, Leader_ID, Follower_ID\n",
        "        \n",
        "        Returns:\n",
        "        List of validated CarFollowingPair objects\n",
        "        \"\"\"\n",
        "        valid_pairs = []\n",
        "        pairs_before_validation = 0\n",
        "        pairs_after_validation = 0\n",
        "        \n",
        "        # Step 1: Group data by lane\n",
        "        for lane_id, lane_data in df.groupby('Lane_ID'):\n",
        "            # Skip special lanes (like merge lanes or shoulders)\n",
        "            if lane_id > 6:  # Assuming regular lanes are 1-6\n",
        "                continue\n",
        "                \n",
        "            # Step 2: Process each time window in the lane\n",
        "            frames = sorted(lane_data['Frame_ID'].unique())\n",
        "            \n",
        "            # Step 3: Track ongoing pairs\n",
        "            current_pairs = {}\n",
        "            \n",
        "            for frame in frames:\n",
        "                frame_data = lane_data[lane_data['Frame_ID'] == frame]\n",
        "                \n",
        "                # Sort vehicles by position to identify leader-follower relationships\n",
        "                frame_vehicles = frame_data.sort_values('LocalY', ascending=False)\n",
        "                \n",
        "                # Step 4: Check each consecutive pair of vehicles\n",
        "                for i in range(len(frame_vehicles) - 1):\n",
        "                    leader = frame_vehicles.iloc[i]\n",
        "                    follower = frame_vehicles.iloc[i + 1]\n",
        "                    \n",
        "                    # Calculate spacing\n",
        "                    spacing = leader['LocalY'] - follower['LocalY']\n",
        "                    pairs_before_validation += 1\n",
        "                    \n",
        "                    # Get vehicle IDs for relationship validation\n",
        "                    leader_id = leader['Vehicle_ID']\n",
        "                    follower_id = follower['Vehicle_ID']\n",
        "                    follower_leader_id = follower['Leader_ID']\n",
        "                    leader_follower_id = leader['Follower_ID']\n",
        "                    \n",
        "                    # Validate the leader-follower relationship:\n",
        "                    # 1. If explicit relationships exist (non -1), they must be correct\n",
        "                    # 2. If no explicit relationships (-1), allow validation by spacing\n",
        "                    valid_relationship = False\n",
        "                    \n",
        "                    if follower_leader_id != -1 or leader_follower_id != -1:\n",
        "                        # At least one explicit relationship exists - it must be correct\n",
        "                        leader_match = follower_leader_id == leader_id\n",
        "                        follower_match = leader_follower_id == follower_id\n",
        "                        valid_relationship = leader_match or follower_match\n",
        "                    else:\n",
        "                        # No explicit relationships - allow validation by spacing\n",
        "                        valid_relationship = True\n",
        "                    \n",
        "                    # Both the relationship and spacing must be valid\n",
        "                    if valid_relationship and self.min_spacing <= spacing <= self.max_spacing:\n",
        "                        pairs_after_validation += 1\n",
        "                        pair_id = (leader_id, follower_id)\n",
        "                        \n",
        "                        if pair_id not in current_pairs:\n",
        "                            # Start new pair tracking\n",
        "                            current_pairs[pair_id] = {\n",
        "                                'start_frame': frame,\n",
        "                                'current_frame': frame,\n",
        "                                'lane_id': lane_id\n",
        "                            }\n",
        "                        else:\n",
        "                            # Update existing pair\n",
        "                            current_pairs[pair_id]['current_frame'] = frame\n",
        "                    else:\n",
        "                        # Invalid pair - end pair if exists\n",
        "                        pair_id = (leader_id, follower_id)\n",
        "                        self._check_and_add_pair(current_pairs, pair_id, valid_pairs)\n",
        "                \n",
        "            # Process any remaining pairs at the end of the lane\n",
        "            for pair_id in list(current_pairs.keys()):\n",
        "                self._check_and_add_pair(current_pairs, pair_id, valid_pairs)\n",
        "        \n",
        "        print(f\"Pairs before validation: {pairs_before_validation}\")\n",
        "        print(f\"Pairs after validation: {pairs_after_validation}\")\n",
        "        return valid_pairs\n",
        "    \n",
        "    def _check_and_add_pair(self, current_pairs: Dict, \n",
        "                           pair_id: Tuple[int, int],\n",
        "                           valid_pairs: List[CarFollowingPair]) -> None:\n",
        "        \"\"\"\n",
        "        Validates and adds a car-following pair if it meets duration criteria\n",
        "        \"\"\"\n",
        "        if pair_id in current_pairs:\n",
        "            pair_data = current_pairs[pair_id]\n",
        "            duration_frames = pair_data['current_frame'] - pair_data['start_frame'] + 1\n",
        "            \n",
        "            if duration_frames >= self.min_frames:\n",
        "                # Create validated pair\n",
        "                valid_pairs.append(CarFollowingPair(\n",
        "                    leader_id=pair_id[0],\n",
        "                    follower_id=pair_id[1],\n",
        "                    start_frame=pair_data['start_frame'],\n",
        "                    end_frame=pair_data['current_frame'],\n",
        "                    lane_id=pair_data['lane_id']\n",
        "                ))\n",
        "            \n",
        "            # Remove pair from tracking\n",
        "            del current_pairs[pair_id]\n",
        "    \n",
        "    def compute_pair_metrics(self, pair: CarFollowingPair, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"\n",
        "        Computes detailed metrics for a validated car-following pair with proper handling of zero speeds\n",
        "        \n",
        "        Parameters:\n",
        "        pair: CarFollowingPair object\n",
        "        df: Original trajectory DataFrame\n",
        "        \n",
        "        Returns:\n",
        "        Dictionary of computed metrics\n",
        "        \"\"\"\n",
        "        # Get leader and follower trajectories\n",
        "        leader_data = df[(df['Vehicle_ID'] == pair.leader_id) & \n",
        "                        (df['Frame_ID'] >= pair.start_frame) & \n",
        "                        (df['Frame_ID'] <= pair.end_frame)]\n",
        "        \n",
        "        follower_data = df[(df['Vehicle_ID'] == pair.follower_id) & \n",
        "                        (df['Frame_ID'] >= pair.start_frame) & \n",
        "                        (df['Frame_ID'] <= pair.end_frame)]\n",
        "        \n",
        "        # Compute spacing statistics\n",
        "        spacing = leader_data['LocalY'].values - follower_data['LocalY'].values\n",
        "        \n",
        "        # Compute speed difference statistics\n",
        "        speed_diff = leader_data['Speed'].values - follower_data['Speed'].values\n",
        "        \n",
        "        # Compute time headway with careful handling of zero speeds\n",
        "        follower_speeds = follower_data['Speed'].values\n",
        "        \n",
        "        # Create a mask for non-zero speeds to avoid division by zero\n",
        "        non_zero_speed_mask = follower_speeds > 0.01  # Small threshold to handle near-zero speeds\n",
        "        \n",
        "        # Only calculate time headway where speed is non-zero\n",
        "        if np.any(non_zero_speed_mask):\n",
        "            # Calculate time headway only for non-zero speeds\n",
        "            valid_spacings = spacing[non_zero_speed_mask]\n",
        "            valid_speeds = follower_speeds[non_zero_speed_mask]\n",
        "            time_headway = valid_spacings / valid_speeds\n",
        "            \n",
        "            # Remove any extreme values that might still occur\n",
        "            reasonable_headway_mask = (time_headway > 0) & (time_headway < 20)  # Filter unreasonable values\n",
        "            valid_headway = time_headway[reasonable_headway_mask] if np.any(reasonable_headway_mask) else np.array([])\n",
        "        else:\n",
        "            # No valid speeds for calculation\n",
        "            valid_headway = np.array([])\n",
        "        \n",
        "        # Handle empty arrays for edge cases\n",
        "        if len(valid_headway) == 0:\n",
        "            headway_stats = {\n",
        "                'mean': np.nan,\n",
        "                'std': np.nan,\n",
        "                'min': np.nan,\n",
        "                'max': np.nan\n",
        "            }\n",
        "        else:\n",
        "            headway_stats = {\n",
        "                'mean': np.mean(valid_headway),\n",
        "                'std': np.std(valid_headway),\n",
        "                'min': np.min(valid_headway),\n",
        "                'max': np.max(valid_headway)\n",
        "            }\n",
        "        \n",
        "        return {\n",
        "            'spacing': {\n",
        "                'mean': np.mean(spacing),\n",
        "                'std': np.std(spacing),\n",
        "                'min': np.min(spacing),\n",
        "                'max': np.max(spacing)\n",
        "            },\n",
        "            'speed_difference': {\n",
        "                'mean': np.mean(speed_diff),\n",
        "                'std': np.std(speed_diff),\n",
        "                'min': np.min(speed_diff),\n",
        "                'max': np.max(speed_diff)\n",
        "            },\n",
        "            'time_headway': headway_stats\n",
        "        }\n",
        "\n",
        "def main():\n",
        "    # Example usage\n",
        "    # Read the data file\n",
        "    df = pd.read_csv(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\DATA (NO MOTORCYCLES).txt\", delimiter='\\s+', header=None,\n",
        "                     names=['Vehicle_ID', 'Frame_ID', 'Lane_ID', 'LocalY',\n",
        "                           'Speed', 'Acceleration', 'Vehicle_Length',\n",
        "                           'Vehicle_Class', 'Follower_ID', 'Leader_ID'])\n",
        "    \n",
        "    # Initialize identifier\n",
        "    identifier = CarFollowingIdentifier(\n",
        "        min_duration=20.0,  # 20 seconds minimum\n",
        "        min_spacing=2.0,    # 2 meters minimum spacing\n",
        "        max_spacing=100.0   # 100 meters maximum spacing\n",
        "    )\n",
        "    \n",
        "    # Find car-following pairs\n",
        "    all_pairs = identifier.identify_pairs(df)\n",
        "    \n",
        "    # Print summary\n",
        "    print(f\"Found {len(all_pairs)} valid car-following pairs\")\n",
        "    \n",
        "    # Export all pairs to CSV\n",
        "    export_pairs_to_csv(all_pairs, df, identifier, \"all_car_following_pairs.csv\")\n",
        "    \n",
        "    # Select the specific pairs we want\n",
        "    selected_pairs = []\n",
        "    selected_pair_ids = [\n",
        "        (1087.0, 1101.0),  # Pair 57 - Aggressive Following with Large Speed Difference\n",
        "        (120.0, 125.0),    # Pair 13 - Very Close Following\n",
        "        (2066.0, 2074.0),  # Pair 96 - Conservative Following with Large Spacing\n",
        "        (1463.0, 1478.0),  # Pair 714 - Lane 3 with Medium Following Distance\n",
        "        (260.0, 267.0)     # Pair 238 - Stable Following with Small Speed Difference\n",
        "    ]\n",
        "    \n",
        "    # Find these pairs in our identified pairs\n",
        "    for pair in all_pairs:\n",
        "        if (pair.leader_id, pair.follower_id) in selected_pair_ids:\n",
        "            selected_pairs.append(pair)\n",
        "    \n",
        "    print(f\"Selected {len(selected_pairs)} specific car-following pairs for analysis\")\n",
        "    \n",
        "    # Export selected pairs to a separate CSV\n",
        "    export_pairs_to_csv(selected_pairs, df, identifier, \"selected_car_following_pairs.csv\")\n",
        "    \n",
        "    # Analyze each selected pair\n",
        "    for i, pair in enumerate(selected_pairs):\n",
        "        print(f\"\\nPair {i+1}:\")\n",
        "        print(f\"Leader ID: {pair.leader_id}\")\n",
        "        print(f\"Follower ID: {pair.follower_id}\")\n",
        "        print(f\"Duration: {pair.duration:.1f} seconds\")\n",
        "        print(f\"Lane: {pair.lane_id}\")\n",
        "        \n",
        "        # Compute and print metrics\n",
        "        metrics = identifier.compute_pair_metrics(pair, df)\n",
        "        print(\"\\nMetrics:\")\n",
        "        for metric, values in metrics.items():\n",
        "            print(f\"\\n{metric}:\")\n",
        "            for stat, value in values.items():\n",
        "                print(f\"  {stat}: {value:.2f}\")\n",
        "\n",
        "def export_pairs_to_csv(pairs, df, identifier, filename):\n",
        "    \"\"\"\n",
        "    Export all car-following pairs with their metrics to a CSV file\n",
        "    \n",
        "    Parameters:\n",
        "    pairs: List of CarFollowingPair objects\n",
        "    df: Original trajectory DataFrame\n",
        "    identifier: CarFollowingIdentifier instance for computing metrics\n",
        "    filename: Name of the output CSV file\n",
        "    \"\"\"\n",
        "    # Prepare a list to hold all pair data\n",
        "    all_pairs_data = []\n",
        "    \n",
        "    # Process each pair\n",
        "    for i, pair in enumerate(pairs):\n",
        "        # Compute metrics for this pair\n",
        "        metrics = identifier.compute_pair_metrics(pair, df)\n",
        "        \n",
        "        # Create a dictionary with all relevant data\n",
        "        pair_data = {\n",
        "            'pair_id': i + 1,\n",
        "            'leader_id': pair.leader_id,\n",
        "            'follower_id': pair.follower_id,\n",
        "            'start_frame': pair.start_frame,\n",
        "            'end_frame': pair.end_frame,\n",
        "            'lane_id': pair.lane_id,\n",
        "            'duration_seconds': pair.duration,\n",
        "            'mean_spacing': metrics['spacing']['mean'],\n",
        "            'std_spacing': metrics['spacing']['std'],\n",
        "            'min_spacing': metrics['spacing']['min'],\n",
        "            'max_spacing': metrics['spacing']['max'],\n",
        "            'mean_speed_diff': metrics['speed_difference']['mean'],\n",
        "            'std_speed_diff': metrics['speed_difference']['std'],\n",
        "            'min_speed_diff': metrics['speed_difference']['min'],\n",
        "            'max_speed_diff': metrics['speed_difference']['max'],\n",
        "            'mean_time_headway': metrics['time_headway']['mean'],\n",
        "            'std_time_headway': metrics['time_headway']['std'],\n",
        "            'min_time_headway': metrics['time_headway']['min'],\n",
        "            'max_time_headway': metrics['time_headway']['max']\n",
        "        }\n",
        "        \n",
        "        all_pairs_data.append(pair_data)\n",
        "    \n",
        "    # Convert to DataFrame\n",
        "    pairs_df = pd.DataFrame(all_pairs_data)\n",
        "    \n",
        "    # Save to CSV\n",
        "    pairs_df.to_csv(filename, index=False)\n",
        "    print(f\"Exported {len(pairs)} car-following pairs to {filename}\")\n",
        "        \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyzes statistical properties of car-following pairs and generates comprehensive visualizations and analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Car-Following Visualization and Calibration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code uses the car_following_pairs.csv file generated from the previous code to analyze the car-following pairs and plot the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-22 16:01:17,872 - __main__ - INFO - Loading trajectory data...\n",
            "2025-02-22 16:01:17,872 - __main__ - INFO - Loading trajectory data...\n",
            "2025-02-22 16:01:17,872 - __main__ - INFO - Loading trajectory data...\n",
            "2025-02-22 16:01:17,872 - __main__ - INFO - Loading trajectory data...\n",
            "2025-02-22 16:01:17,872 - __main__ - INFO - Loading trajectory data...\n",
            "2025-02-22 16:01:20,742 - __main__ - INFO - Successfully loaded data with 1055801 rows\n",
            "2025-02-22 16:01:20,742 - __main__ - INFO - Successfully loaded data with 1055801 rows\n",
            "2025-02-22 16:01:20,742 - __main__ - INFO - Successfully loaded data with 1055801 rows\n",
            "2025-02-22 16:01:20,742 - __main__ - INFO - Successfully loaded data with 1055801 rows\n",
            "2025-02-22 16:01:20,742 - __main__ - INFO - Successfully loaded data with 1055801 rows\n",
            "2025-02-22 16:01:20,746 - __main__ - INFO - Loading selected car-following pairs from selected_car_following_pairs.csv...\n",
            "2025-02-22 16:01:20,746 - __main__ - INFO - Loading selected car-following pairs from selected_car_following_pairs.csv...\n",
            "2025-02-22 16:01:20,746 - __main__ - INFO - Loading selected car-following pairs from selected_car_following_pairs.csv...\n",
            "2025-02-22 16:01:20,746 - __main__ - INFO - Loading selected car-following pairs from selected_car_following_pairs.csv...\n",
            "2025-02-22 16:01:20,746 - __main__ - INFO - Loading selected car-following pairs from selected_car_following_pairs.csv...\n",
            "2025-02-22 16:01:20,757 - __main__ - INFO - Loaded 5 car-following pairs from selected_car_following_pairs.csv\n",
            "2025-02-22 16:01:20,757 - __main__ - INFO - Loaded 5 car-following pairs from selected_car_following_pairs.csv\n",
            "2025-02-22 16:01:20,757 - __main__ - INFO - Loaded 5 car-following pairs from selected_car_following_pairs.csv\n",
            "2025-02-22 16:01:20,757 - __main__ - INFO - Loaded 5 car-following pairs from selected_car_following_pairs.csv\n",
            "2025-02-22 16:01:20,757 - __main__ - INFO - Loaded 5 car-following pairs from selected_car_following_pairs.csv\n",
            "2025-02-22 16:01:20,763 - __main__ - INFO - Processing and visualizing selected pairs...\n",
            "2025-02-22 16:01:20,763 - __main__ - INFO - Processing and visualizing selected pairs...\n",
            "2025-02-22 16:01:20,763 - __main__ - INFO - Processing and visualizing selected pairs...\n",
            "2025-02-22 16:01:20,763 - __main__ - INFO - Processing and visualizing selected pairs...\n",
            "2025-02-22 16:01:20,763 - __main__ - INFO - Processing and visualizing selected pairs...\n",
            "2025-02-22 16:01:22,488 - __main__ - INFO - Saved visualization to visualizations/pair_120.0-125.0_analysis.png\n",
            "2025-02-22 16:01:22,488 - __main__ - INFO - Saved visualization to visualizations/pair_120.0-125.0_analysis.png\n",
            "2025-02-22 16:01:22,488 - __main__ - INFO - Saved visualization to visualizations/pair_120.0-125.0_analysis.png\n",
            "2025-02-22 16:01:22,488 - __main__ - INFO - Saved visualization to visualizations/pair_120.0-125.0_analysis.png\n",
            "2025-02-22 16:01:22,488 - __main__ - INFO - Saved visualization to visualizations/pair_120.0-125.0_analysis.png\n",
            "2025-02-22 16:01:24,583 - __main__ - INFO - Saved visualization to visualizations/pair_1087.0-1101.0_analysis.png\n",
            "2025-02-22 16:01:24,583 - __main__ - INFO - Saved visualization to visualizations/pair_1087.0-1101.0_analysis.png\n",
            "2025-02-22 16:01:24,583 - __main__ - INFO - Saved visualization to visualizations/pair_1087.0-1101.0_analysis.png\n",
            "2025-02-22 16:01:24,583 - __main__ - INFO - Saved visualization to visualizations/pair_1087.0-1101.0_analysis.png\n",
            "2025-02-22 16:01:24,583 - __main__ - INFO - Saved visualization to visualizations/pair_1087.0-1101.0_analysis.png\n",
            "2025-02-22 16:01:26,145 - __main__ - INFO - Saved visualization to visualizations/pair_2066.0-2074.0_analysis.png\n",
            "2025-02-22 16:01:26,145 - __main__ - INFO - Saved visualization to visualizations/pair_2066.0-2074.0_analysis.png\n",
            "2025-02-22 16:01:26,145 - __main__ - INFO - Saved visualization to visualizations/pair_2066.0-2074.0_analysis.png\n",
            "2025-02-22 16:01:26,145 - __main__ - INFO - Saved visualization to visualizations/pair_2066.0-2074.0_analysis.png\n",
            "2025-02-22 16:01:26,145 - __main__ - INFO - Saved visualization to visualizations/pair_2066.0-2074.0_analysis.png\n",
            "2025-02-22 16:01:27,693 - __main__ - INFO - Saved visualization to visualizations/pair_260.0-267.0_analysis.png\n",
            "2025-02-22 16:01:27,693 - __main__ - INFO - Saved visualization to visualizations/pair_260.0-267.0_analysis.png\n",
            "2025-02-22 16:01:27,693 - __main__ - INFO - Saved visualization to visualizations/pair_260.0-267.0_analysis.png\n",
            "2025-02-22 16:01:27,693 - __main__ - INFO - Saved visualization to visualizations/pair_260.0-267.0_analysis.png\n",
            "2025-02-22 16:01:27,693 - __main__ - INFO - Saved visualization to visualizations/pair_260.0-267.0_analysis.png\n",
            "2025-02-22 16:01:29,186 - __main__ - INFO - Saved visualization to visualizations/pair_1463.0-1478.0_analysis.png\n",
            "2025-02-22 16:01:29,186 - __main__ - INFO - Saved visualization to visualizations/pair_1463.0-1478.0_analysis.png\n",
            "2025-02-22 16:01:29,186 - __main__ - INFO - Saved visualization to visualizations/pair_1463.0-1478.0_analysis.png\n",
            "2025-02-22 16:01:29,186 - __main__ - INFO - Saved visualization to visualizations/pair_1463.0-1478.0_analysis.png\n",
            "2025-02-22 16:01:29,186 - __main__ - INFO - Saved visualization to visualizations/pair_1463.0-1478.0_analysis.png\n",
            "2025-02-22 16:01:29,190 - __main__ - INFO - Analysis complete! Visualizations saved to visualizations/\n",
            "2025-02-22 16:01:29,190 - __main__ - INFO - Analysis complete! Visualizations saved to visualizations/\n",
            "2025-02-22 16:01:29,190 - __main__ - INFO - Analysis complete! Visualizations saved to visualizations/\n",
            "2025-02-22 16:01:29,190 - __main__ - INFO - Analysis complete! Visualizations saved to visualizations/\n",
            "2025-02-22 16:01:29,190 - __main__ - INFO - Analysis complete! Visualizations saved to visualizations/\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "\n",
        "# Configure logger\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "handler = logging.StreamHandler()\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load and process the trajectory data\"\"\"\n",
        "    try:\n",
        "        # Read data with numbered columns first\n",
        "        data = pd.read_csv(file_path, delimiter='\\s+', header=None)\n",
        "        \n",
        "        # Rename columns to match expected format\n",
        "        data.columns = ['Vehicle_ID', 'Frame_ID', 'Lane_ID', 'Local_Y', \n",
        "                       'Speed', 'Acceleration', 'Vehicle_Length',\n",
        "                       'Vehicle_Class', 'Follower_ID', 'Leader_ID']\n",
        "        \n",
        "        logger.info(f\"Successfully loaded data with {len(data)} rows\")\n",
        "        return data\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading data: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def load_car_following_pairs(csv_file):\n",
        "    \"\"\"\n",
        "    Load previously identified car-following pairs from a CSV file\n",
        "    \n",
        "    Parameters:\n",
        "    csv_file: Path to the CSV file containing car-following pairs\n",
        "    \n",
        "    Returns:\n",
        "    List of dictionaries with car-following pair information\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the CSV file\n",
        "        pairs_df = pd.read_csv(csv_file)\n",
        "        logger.info(f\"Loaded {len(pairs_df)} car-following pairs from {csv_file}\")\n",
        "        \n",
        "        # Convert dataframe rows to dictionaries for compatibility with existing code\n",
        "        pairs = []\n",
        "        for _, row in pairs_df.iterrows():\n",
        "            pairs.append({\n",
        "                'leader_id': row['leader_id'],\n",
        "                'follower_id': row['follower_id'],\n",
        "                'start_frame': row['start_frame'],\n",
        "                'end_frame': row['end_frame'],\n",
        "                'lane': row['lane_id'] if 'lane_id' in row else row.get('lane', 1),  # Handle both column naming conventions\n",
        "                'duration': row['duration_seconds'] if 'duration_seconds' in row else \n",
        "                           (row['end_frame'] - row['start_frame'] + 1) * 0.1\n",
        "            })\n",
        "        \n",
        "        return pairs\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading car-following pairs: {e}\")\n",
        "        return []\n",
        "\n",
        "def process_pair_data(data, selected_pairs):\n",
        "    \"\"\"Process data for selected car-following pairs\"\"\"\n",
        "    pair_data = []\n",
        "    \n",
        "    for i, pair in enumerate(selected_pairs):\n",
        "        # Get trajectory data for leader and follower\n",
        "        frames = range(int(pair['start_frame']), int(pair['end_frame']) + 1)\n",
        "        \n",
        "        leader_data = data[\n",
        "            (data['Vehicle_ID'] == pair['leader_id']) & \n",
        "            (data['Frame_ID'].isin(frames))\n",
        "        ].sort_values('Frame_ID')\n",
        "        \n",
        "        follower_data = data[\n",
        "            (data['Vehicle_ID'] == pair['follower_id']) & \n",
        "            (data['Frame_ID'].isin(frames))\n",
        "        ].sort_values('Frame_ID')\n",
        "        \n",
        "        # Combine data\n",
        "        merged_data = pd.merge(\n",
        "            leader_data, \n",
        "            follower_data,\n",
        "            on='Frame_ID',\n",
        "            suffixes=('_leader', '_follower')\n",
        "        )\n",
        "        \n",
        "        time_data = []\n",
        "        for _, row in merged_data.iterrows():\n",
        "            time_data.append({\n",
        "                'time': (row['Frame_ID'] - pair['start_frame']) * 0.1,\n",
        "                'leader_speed': row['Speed_leader'],\n",
        "                'follower_speed': row['Speed_follower'],\n",
        "                'spacing': row['Local_Y_leader'] - row['Local_Y_follower'],\n",
        "                'relative_speed': row['Speed_leader'] - row['Speed_follower']\n",
        "            })\n",
        "        \n",
        "        # Skip pairs with empty merged data\n",
        "        if not time_data:\n",
        "            logger.warning(f\"Skipping pair {i+1} ({pair['leader_id']}-{pair['follower_id']}) due to empty merged data\")\n",
        "            continue\n",
        "        \n",
        "        pair_data.append({\n",
        "            'pair_id': f\"{pair['leader_id']}-{pair['follower_id']}\",\n",
        "            'time_data': pd.DataFrame(time_data)\n",
        "        })\n",
        "    \n",
        "    return pair_data\n",
        "\n",
        "def plot_pair_visualizations(pair_data, output_dir=\".\"):\n",
        "    \"\"\"Create visualizations for car-following pairs\"\"\"\n",
        "    for pair in pair_data:\n",
        "        time_data = pair['time_data']\n",
        "        \n",
        "        fig, axes = plt.subplots(3, 1, figsize=(12, 15))\n",
        "        fig.suptitle(f\"Car-Following Pair Analysis: Pair {pair['pair_id']}\", fontsize=16 )\n",
        "        \n",
        "        # Speed profiles\n",
        "        axes[0].plot(time_data['time'], time_data['leader_speed'], \n",
        "                    label='Leader', color='#3B39FF', linewidth=2)\n",
        "        axes[0].plot(time_data['time'], time_data['follower_speed'], \n",
        "                    label='Follower', color='#FF4040', linestyle='--', linewidth=2)\n",
        "        axes[0].set_xlabel('Time (s)')\n",
        "        axes[0].set_ylabel('Speed (m/s)')\n",
        "        axes[0].set_title('Speed Profiles')\n",
        "        axes[0].grid(True)\n",
        "        axes[0].legend()\n",
        "        \n",
        "        # Space gap\n",
        "        axes[1].plot(time_data['time'], time_data['spacing'], \n",
        "                    color='green', linewidth=2)\n",
        "        axes[1].set_xlabel('Time (s)')\n",
        "        axes[1].set_ylabel('Space Gap (m)')\n",
        "        axes[1].set_title('Following Distance')\n",
        "        axes[1].grid(True)\n",
        "        \n",
        "        # Relative speed\n",
        "        axes[2].plot(time_data['time'], time_data['relative_speed'], \n",
        "                    color='purple', linewidth=2)\n",
        "        axes[2].set_xlabel('Time (s)')\n",
        "        axes[2].set_ylabel('Relative Speed (m/s)')\n",
        "        axes[2].set_title('Relative Speed (Leader - Follower)')\n",
        "        axes[2].grid(True)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        stats_text = (\n",
        "            f\"Mean Space Gap: {time_data['spacing'].mean():.1f}m\\n\"\n",
        "            f\"Mean Relative Speed: {time_data['relative_speed'].mean():.2f}m/s\\n\"\n",
        "            f\"Duration: {len(time_data)*0.1:.1f}s\"\n",
        "        )\n",
        "        plt.figtext(0.02, 0.02, stats_text, fontsize=10, \n",
        "                   bbox=dict(facecolor='white', alpha=0.8))\n",
        "        \n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "        output_path = f\"{output_dir}/pair_{pair['pair_id']}_analysis.png\"\n",
        "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "        logger.info(f\"Saved visualization to {output_path}\")\n",
        "        plt.close()\n",
        "\n",
        "def main():\n",
        "    # Define file paths\n",
        "    data_file = \"D:/ASU Academics/Traffic Flow Theroy/MP-1/Reconstructed NGSIM I80-1 data/Data/DATA (NO MOTORCYCLES).txt\"\n",
        "    pairs_csv = \"selected_car_following_pairs.csv\"  # Use the selected pairs CSV from first code\n",
        "    output_dir = \"visualizations\"\n",
        "    \n",
        "    # Create output directory if it doesn't exist\n",
        "    import os\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    # Load trajectory data\n",
        "    logger.info(\"Loading trajectory data...\")\n",
        "    data = load_data(data_file)\n",
        "    \n",
        "    if len(data) == 0:\n",
        "        logger.error(\"Failed to load trajectory data\")\n",
        "        return\n",
        "    \n",
        "    # Load specific selected car-following pairs from CSV\n",
        "    logger.info(f\"Loading selected car-following pairs from {pairs_csv}...\")\n",
        "    pairs = load_car_following_pairs(pairs_csv)\n",
        "    \n",
        "    if len(pairs) == 0:\n",
        "        logger.error(f\"No car-following pairs found in {pairs_csv}\")\n",
        "        return\n",
        "    \n",
        "    # Process and visualize pairs\n",
        "    logger.info(\"Processing and visualizing selected pairs...\")\n",
        "    pair_data = process_pair_data(data, pairs)\n",
        "    \n",
        "    if len(pair_data) == 0:\n",
        "        logger.error(\"No valid pair data generated for visualization\")\n",
        "        return\n",
        "    \n",
        "    plot_pair_visualizations(pair_data, output_dir)\n",
        "    \n",
        "    logger.info(f\"Analysis complete! Visualizations saved to {output_dir}/\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Lane Change Analysis :** Count the lane-change occurrences in the dataset. Analyze where and when these lane changes occur, identifying any observable trends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading data file...\n",
            "Analyzing lane changes...\n",
            "Generating statistics...\n",
            "\n",
            "Lane Change Analysis Summary:\n",
            "Total lane changes: 204\n",
            "\n",
            "Direction distribution:\n",
            "right: 172 (84.3%)\n",
            "left: 32 (15.7%)\n",
            "\n",
            "Average duration: 15.26 seconds\n",
            "\n",
            "Speed statistics during lane changes:\n",
            "mean: 7.86 m/s\n",
            "std: 2.44 m/s\n",
            "min: 0.97 m/s\n",
            "max: 14.77 m/s\n",
            "\n",
            "Creating visualizations...\n",
            "Analysis complete. Visualizations saved as 'lane_change_analysis.png'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "class LaneChangeAnalyzer:\n",
        "    def __init__(self, min_duration: float = 0.5):\n",
        "        self.min_duration = min_duration\n",
        "        self.min_frames = int(min_duration * 10)\n",
        "        self.lane_changes = []\n",
        "        \n",
        "    def analyze_trajectories(self, df: pd.DataFrame) -> None:\n",
        "        \"\"\"Analyzes trajectory data to identify lane changes\"\"\"\n",
        "        # First, rename columns to match our expected format\n",
        "        df.columns = ['Vehicle_ID', 'Frame_ID', 'Lane_ID', 'LocalY',\n",
        "                     'Speed', 'Acceleration', 'Vehicle_Length',\n",
        "                     'Vehicle_Class', 'Follower_ID', 'Leader_ID']\n",
        "        \n",
        "        # Group by vehicle\n",
        "        for vehicle_id in df['Vehicle_ID'].unique():\n",
        "            # Get vehicle's trajectory\n",
        "            vehicle_data = df[df['Vehicle_ID'] == vehicle_id].sort_values('Frame_ID')\n",
        "            \n",
        "            # Initialize variables for tracking lane changes\n",
        "            prev_lane = None\n",
        "            start_frame = None\n",
        "            from_lane = None\n",
        "            \n",
        "            # Analyze frame by frame\n",
        "            for idx, row in vehicle_data.iterrows():\n",
        "                curr_lane = row['Lane_ID']\n",
        "                \n",
        "                if prev_lane is not None and curr_lane != prev_lane:\n",
        "                    if start_frame is None:\n",
        "                        # Start of lane change\n",
        "                        start_frame = row['Frame_ID']\n",
        "                        from_lane = prev_lane\n",
        "                    elif curr_lane != from_lane:\n",
        "                        # End of lane change\n",
        "                        end_frame = row['Frame_ID']\n",
        "                        duration = (end_frame - start_frame) * 0.1\n",
        "                        \n",
        "                        if duration >= self.min_duration:\n",
        "                            self.lane_changes.append({\n",
        "                                'vehicle_id': vehicle_id,\n",
        "                                'start_frame': start_frame,\n",
        "                                'end_frame': end_frame,\n",
        "                                'from_lane': from_lane,\n",
        "                                'to_lane': curr_lane,\n",
        "                                'position': row['LocalY'],\n",
        "                                'speed': row['Speed'],\n",
        "                                'duration': duration,\n",
        "                                'direction': 'left' if curr_lane > from_lane else 'right'\n",
        "                            })\n",
        "                        \n",
        "                        # Reset for next lane change but immediately start tracking a potential new lane change\n",
        "                        start_frame = row['Frame_ID']  # Start tracking a new lane change immediately\n",
        "                        from_lane = prev_lane  # The lane we just left might be the start of a new lane change\n",
        "                \n",
        "                prev_lane = curr_lane\n",
        "    \n",
        "    def generate_statistics(self) -> dict:\n",
        "        \"\"\"Generates summary statistics of lane changes\"\"\"\n",
        "        if not self.lane_changes:\n",
        "            return {\n",
        "                'total_changes': 0,\n",
        "                'direction_counts': {'left': 0, 'right': 0},\n",
        "                'avg_duration': 0,\n",
        "                'speed_stats': {'mean': 0, 'std': 0, 'min': 0, 'max': 0}\n",
        "            }\n",
        "            \n",
        "        df_changes = pd.DataFrame(self.lane_changes)\n",
        "        \n",
        "        stats = {\n",
        "            'total_changes': len(self.lane_changes),\n",
        "            'direction_counts': df_changes['direction'].value_counts().to_dict(),\n",
        "            'avg_duration': df_changes['duration'].mean(),\n",
        "            'speed_stats': {\n",
        "                'mean': df_changes['speed'].mean(),\n",
        "                'std': df_changes['speed'].std(),\n",
        "                'min': df_changes['speed'].min(),\n",
        "                'max': df_changes['speed'].max()\n",
        "            },\n",
        "            'lane_transitions': pd.crosstab(\n",
        "                df_changes['from_lane'],\n",
        "                df_changes['to_lane']\n",
        "            ).to_dict(),\n",
        "            'position_dist': pd.cut(\n",
        "                df_changes['position'],\n",
        "                bins=np.arange(0, df_changes['position'].max() + 100, 100)\n",
        "            ).value_counts().sort_index().to_dict()\n",
        "        }\n",
        "        \n",
        "        return stats\n",
        "    \n",
        "    def plot_analysis(self, stats: dict) -> None:\n",
        "        \"\"\"Creates visualizations of lane change patterns\"\"\"\n",
        "        fig = plt.figure(figsize=(15, 10))\n",
        "        \n",
        "        # 1. Direction Distribution (Top Left)\n",
        "        plt.subplot(221)\n",
        "        directions = list(stats['direction_counts'].keys())\n",
        "        counts = list(stats['direction_counts'].values())\n",
        "        plt.bar(directions, counts)\n",
        "        plt.title('Lane Change Direction Distribution')\n",
        "        plt.ylabel('Number of Lane Changes')\n",
        "        \n",
        "        # 2. Position Distribution (Top Right)\n",
        "        plt.subplot(222)\n",
        "        positions = list(stats['position_dist'].keys())\n",
        "        position_counts = list(stats['position_dist'].values())\n",
        "        plt.bar(range(len(positions)), position_counts)\n",
        "        plt.title('Lane Change Position Distribution')\n",
        "        plt.xlabel('Position (100m segments)')\n",
        "        plt.ylabel('Number of Lane Changes')\n",
        "        \n",
        "        # 3. Lane Transitions Heatmap (Bottom Left)\n",
        "        plt.subplot(223)\n",
        "        if self.lane_changes:\n",
        "            df_changes = pd.DataFrame(self.lane_changes)\n",
        "            transition_matrix = pd.crosstab(\n",
        "                df_changes['from_lane'],\n",
        "                df_changes['to_lane']\n",
        "            )\n",
        "            sns.heatmap(transition_matrix, annot=True, fmt='d', cmap='YlOrRd')\n",
        "            plt.title('Lane Change Transitions')\n",
        "            plt.xlabel('To Lane')\n",
        "            plt.ylabel('From Lane')\n",
        "                    \n",
        "        # 4. Speed Distribution (Bottom Right)\n",
        "        plt.subplot(224)\n",
        "        if self.lane_changes:\n",
        "            speeds = [lc['speed'] for lc in self.lane_changes]\n",
        "            plt.hist(speeds, bins=20)\n",
        "            plt.title('Speed During Lane Changes')\n",
        "            plt.xlabel('Speed (m/s)')\n",
        "            plt.ylabel('Frequency')\n",
        "                    \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('lane_change_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "def main():\n",
        "    # Read data file\n",
        "    print(\"Reading data file...\")\n",
        "    df = pd.read_csv(\"D:/ASU Academics/Traffic Flow Theroy/MP-1/Reconstructed NGSIM I80-1 data/Data/DATA (NO MOTORCYCLES).txt\", delimiter='\\s+', header=None)\n",
        "    \n",
        "    # Initialize analyzer\n",
        "    print(\"Analyzing lane changes...\")\n",
        "    analyzer = LaneChangeAnalyzer(min_duration=0.5)\n",
        "    \n",
        "    # Analyze trajectories\n",
        "    analyzer.analyze_trajectories(df)\n",
        "    \n",
        "    # Generate statistics\n",
        "    print(\"Generating statistics...\")\n",
        "    stats = analyzer.generate_statistics()\n",
        "    \n",
        "    # Print summary\n",
        "    print(\"\\nLane Change Analysis Summary:\")\n",
        "    print(f\"Total lane changes: {stats['total_changes']}\")\n",
        "    print(\"\\nDirection distribution:\")\n",
        "    for direction, count in stats['direction_counts'].items():\n",
        "        print(f\"{direction}: {count} ({count/stats['total_changes']*100:.1f}%)\")\n",
        "    print(f\"\\nAverage duration: {stats['avg_duration']:.2f} seconds\")\n",
        "    print(\"\\nSpeed statistics during lane changes:\")\n",
        "    for stat, value in stats['speed_stats'].items():\n",
        "        print(f\"{stat}: {value:.2f} m/s\")\n",
        "    \n",
        "    # Create visualizations\n",
        "    print(\"\\nCreating visualizations...\")\n",
        "    analyzer.plot_analysis(stats)\n",
        "    print(\"Analysis complete. Visualizations saved as 'lane_change_analysis.png'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Time-Space Diagram :** Plot the lane-by-lane time-space diagram for all the NGSIM trajectory data. Based on the diagram, discuss traffic conditions and patterns of congestion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating time-space diagrams...\n",
            "Creating congestion heatmap...\n",
            "\n",
            "Analyzing congestion patterns...\n",
            "\n",
            "Traffic Analysis Summary:\n",
            "\n",
            "Congestion threshold: 10 m/s\n",
            "\n",
            "Lane Statistics:\n",
            "          mean   std   min    max\n",
            "Lane_ID                          \n",
            "1        16.63  3.71  0.58  31.63\n",
            "2         7.11  2.64  0.00  17.74\n",
            "3         7.06  2.47  0.00  16.52\n",
            "4         6.37  2.78  0.00  16.74\n",
            "5         7.02  2.99  0.00  19.24\n",
            "6         6.90  3.14  0.00  20.08\n",
            "7         6.34  4.18  0.00  20.74\n",
            "999      10.76  3.60  0.80  17.77\n",
            "\n",
            "Congestion Periods:\n",
            "Lane 2: Time window (0.0, 300.0], Average speed: 7.3 m/s\n",
            "Lane 2: Time window (300.0, 600.0], Average speed: 7.5 m/s\n",
            "Lane 2: Time window (600.0, 900.0], Average speed: 6.3 m/s\n",
            "Lane 2: Time window (900.0, 1200.0], Average speed: 9.1 m/s\n",
            "Lane 3: Time window (0.0, 300.0], Average speed: 7.6 m/s\n",
            "Lane 3: Time window (300.0, 600.0], Average speed: 7.1 m/s\n",
            "Lane 3: Time window (600.0, 900.0], Average speed: 6.4 m/s\n",
            "Lane 3: Time window (900.0, 1200.0], Average speed: 8.2 m/s\n",
            "Lane 4: Time window (0.0, 300.0], Average speed: 7.5 m/s\n",
            "Lane 4: Time window (300.0, 600.0], Average speed: 7.0 m/s\n",
            "Lane 4: Time window (600.0, 900.0], Average speed: 5.0 m/s\n",
            "Lane 4: Time window (900.0, 1200.0], Average speed: 7.5 m/s\n",
            "Lane 5: Time window (0.0, 300.0], Average speed: 8.0 m/s\n",
            "Lane 5: Time window (300.0, 600.0], Average speed: 8.4 m/s\n",
            "Lane 5: Time window (600.0, 900.0], Average speed: 5.4 m/s\n",
            "Lane 5: Time window (900.0, 1200.0], Average speed: 7.0 m/s\n",
            "Lane 6: Time window (0.0, 300.0], Average speed: 7.2 m/s\n",
            "Lane 6: Time window (300.0, 600.0], Average speed: 8.1 m/s\n",
            "Lane 6: Time window (600.0, 900.0], Average speed: 5.9 m/s\n",
            "Lane 6: Time window (900.0, 1200.0], Average speed: 6.5 m/s\n",
            "Lane 7: Time window (0.0, 300.0], Average speed: 8.1 m/s\n",
            "Lane 7: Time window (300.0, 600.0], Average speed: 7.6 m/s\n",
            "Lane 7: Time window (600.0, 900.0], Average speed: 4.9 m/s\n",
            "Lane 7: Time window (900.0, 1200.0], Average speed: 5.1 m/s\n",
            "Lane 999: Time window (300.0, 600.0], Average speed: 5.2 m/s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Raswanth\\AppData\\Local\\Temp\\ipykernel_70352\\621833389.py:129: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  speed_stats = self.df.groupby(['Lane_ID', 'time_window'])['Speed'].agg([\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.collections import LineCollection\n",
        "import seaborn as sns\n",
        "\n",
        "class TimeSpaceDiagramAnalyzer:\n",
        "    def __init__(self, data_file: str):\n",
        "        \"\"\"Initialize analyzer with data file path\"\"\"\n",
        "        self.df = pd.read_csv(data_file, delimiter='\\s+', header=None,\n",
        "                             names=['Vehicle_ID', 'Frame_ID', 'Lane_ID', 'LocalY',\n",
        "                                   'Speed', 'Acceleration', 'Vehicle_Length',\n",
        "                                   'Vehicle_Class', 'Follower_ID', 'Leader_ID'])\n",
        "        \n",
        "        # Convert Frame_ID to time in seconds\n",
        "        self.df['Time'] = self.df['Frame_ID'] * 0.1\n",
        "        \n",
        "    def plot_lane_diagram(self, lane_id: int, ax=None, cmap='viridis'):\n",
        "        \"\"\"Plot time-space diagram for a specific lane\"\"\"\n",
        "        lane_data = self.df[self.df['Lane_ID'] == lane_id]\n",
        "        \n",
        "        lines = []\n",
        "        colors = []\n",
        "        \n",
        "        for vehicle_id in lane_data['Vehicle_ID'].unique():\n",
        "            vehicle_traj = lane_data[lane_data['Vehicle_ID'] == vehicle_id]\n",
        "            if len(vehicle_traj) > 1:\n",
        "                points = np.column_stack((vehicle_traj['Time'], \n",
        "                                       vehicle_traj['LocalY']))\n",
        "                lines.append(points)\n",
        "                colors.append(np.mean(vehicle_traj['Speed']))\n",
        "        \n",
        "        if not lines:\n",
        "            return None\n",
        "            \n",
        "        lc = LineCollection(lines, cmap=plt.get_cmap(cmap))\n",
        "        lc.set_array(np.array(colors))\n",
        "        \n",
        "        if ax is None:\n",
        "            ax = plt.gca()\n",
        "            \n",
        "        line = ax.add_collection(lc)\n",
        "        \n",
        "        # Set axis limits\n",
        "        times = lane_data['Time']\n",
        "        positions = lane_data['LocalY']\n",
        "        ax.set_xlim(times.min(), times.max())\n",
        "        ax.set_ylim(positions.min(), positions.max())\n",
        "        \n",
        "        return line\n",
        "\n",
        "    def create_full_diagram(self):\n",
        "        \"\"\"Create time-space diagrams for all lanes\"\"\"\n",
        "        lanes = sorted(self.df['Lane_ID'].unique())\n",
        "        n_lanes = len(lanes)\n",
        "        \n",
        "        fig, axes = plt.subplots(n_lanes, 1, figsize=(15, 4*n_lanes), sharex=True)\n",
        "        if n_lanes == 1:\n",
        "            axes = [axes]\n",
        "            \n",
        "        fig.suptitle('Time-Space Diagram by Lane', fontsize=16, y=0.92)\n",
        "        \n",
        "        for ax, lane_id in zip(axes, lanes):\n",
        "            line = self.plot_lane_diagram(lane_id, ax=ax)\n",
        "            if line is not None:\n",
        "                plt.colorbar(line, ax=ax, label='Speed (m/s)')\n",
        "            \n",
        "            ax.set_ylabel('Position (m)')\n",
        "            ax.set_title(f'Lane {lane_id}')\n",
        "            ax.grid(True, linestyle='--', alpha=0.7)\n",
        "            \n",
        "        axes[-1].set_xlabel('Time (seconds)')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        return fig, axes\n",
        "\n",
        "    def plot_congestion_heatmap(self):\n",
        "        \"\"\"Create a heatmap showing average speeds by lane and time\"\"\"\n",
        "        # Calculate time bins (5-minute intervals)\n",
        "        time_bins = np.arange(0, self.df['Time'].max() + 300, 300)\n",
        "        lanes = sorted(self.df['Lane_ID'].unique())\n",
        "        \n",
        "        # Create speed matrix\n",
        "        speed_matrix = np.zeros((len(lanes), len(time_bins)-1))\n",
        "        \n",
        "        for i, lane_id in enumerate(lanes):\n",
        "            lane_data = self.df[self.df['Lane_ID'] == lane_id]\n",
        "            \n",
        "            for j, (t_start, t_end) in enumerate(zip(time_bins[:-1], time_bins[1:])):\n",
        "                mask = (lane_data['Time'] >= t_start) & (lane_data['Time'] < t_end)\n",
        "                avg_speed = lane_data[mask]['Speed'].mean()\n",
        "                speed_matrix[i, j] = avg_speed if not np.isnan(avg_speed) else 0\n",
        "        \n",
        "        # Create figure\n",
        "        fig, ax = plt.subplots(figsize=(15, 5))\n",
        "        \n",
        "        # Create heatmap\n",
        "        im = ax.imshow(speed_matrix, \n",
        "                      aspect='auto',\n",
        "                      cmap='RdYlGn',\n",
        "                      extent=[0, self.df['Time'].max()/60, len(lanes)-0.5, -0.5])\n",
        "        \n",
        "        # Add colorbar\n",
        "        plt.colorbar(im, ax=ax, label='Average Speed (m/s)')\n",
        "        \n",
        "        # Configure axes\n",
        "        ax.set_yticks(range(len(lanes)))\n",
        "        ax.set_yticklabels([f'Lane {lane}' for lane in lanes])\n",
        "        \n",
        "        # Add time labels (in minutes)\n",
        "        time_ticks = np.linspace(0, self.df['Time'].max()/60, 10)\n",
        "        ax.set_xticks(time_ticks)\n",
        "        ax.set_xticklabels([f'{t:.0f}' for t in time_ticks])\n",
        "        \n",
        "        plt.title('Traffic Speed Heatmap')\n",
        "        plt.xlabel('Time (minutes)')\n",
        "        plt.ylabel('Lane')\n",
        "        \n",
        "        return fig, ax\n",
        "\n",
        "    def analyze_congestion(self):\n",
        "        \"\"\"Analyze congestion patterns\"\"\"\n",
        "        congestion_threshold = 10  # m/s\n",
        "        \n",
        "        # Calculate average speeds in 5-minute windows\n",
        "        self.df['time_window'] = pd.cut(self.df['Time'], \n",
        "                                      bins=np.arange(0, self.df['Time'].max() + 300, 300))\n",
        "        \n",
        "        speed_stats = self.df.groupby(['Lane_ID', 'time_window'])['Speed'].agg([\n",
        "            'mean', 'std', 'count'\n",
        "        ]).reset_index()\n",
        "        \n",
        "        # Identify congestion\n",
        "        congestion = speed_stats[speed_stats['mean'] < congestion_threshold]\n",
        "        \n",
        "        # Calculate overall statistics\n",
        "        lane_stats = self.df.groupby('Lane_ID')['Speed'].agg([\n",
        "            'mean', 'std', 'min', 'max'\n",
        "        ]).round(2)\n",
        "        \n",
        "        return {\n",
        "            'congestion_periods': congestion,\n",
        "            'lane_statistics': lane_stats,\n",
        "            'congestion_threshold': congestion_threshold\n",
        "        }\n",
        "\n",
        "def main():\n",
        "    # Initialize analyzer\n",
        "    analyzer = TimeSpaceDiagramAnalyzer(\"D:/ASU Academics/Traffic Flow Theroy/MP-1/Reconstructed NGSIM I80-1 data/Data/DATA (NO MOTORCYCLES).txt\")\n",
        "    \n",
        "    # Create time-space diagrams\n",
        "    print(\"Creating time-space diagrams...\")\n",
        "    fig_ts, axes_ts = analyzer.create_full_diagram()\n",
        "    fig_ts.savefig('time_space_diagram.png', dpi=100, bbox_inches='tight')\n",
        "    plt.close(fig_ts)\n",
        "    \n",
        "    # Create congestion heatmap\n",
        "    print(\"Creating congestion heatmap...\")\n",
        "    fig_heat, ax_heat = analyzer.plot_congestion_heatmap()\n",
        "    fig_heat.savefig('congestion_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close(fig_heat)\n",
        "    \n",
        "    # Analyze congestion\n",
        "    print(\"\\nAnalyzing congestion patterns...\")\n",
        "    stats = analyzer.analyze_congestion()\n",
        "    \n",
        "    # Print summary\n",
        "    print(\"\\nTraffic Analysis Summary:\")\n",
        "    print(f\"\\nCongestion threshold: {stats['congestion_threshold']} m/s\")\n",
        "    \n",
        "    print(\"\\nLane Statistics:\")\n",
        "    print(stats['lane_statistics'])\n",
        "    \n",
        "    print(\"\\nCongestion Periods:\")\n",
        "    congestion = stats['congestion_periods']\n",
        "    if not congestion.empty:\n",
        "        for _, period in congestion.iterrows():\n",
        "            print(f\"Lane {period['Lane_ID']}: \"\n",
        "                  f\"Time window {period['time_window']}, \"\n",
        "                  f\"Average speed: {period['mean']:.1f} m/s\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM0v56CcdsFMwzTHD8CbcyE",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tdsp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
