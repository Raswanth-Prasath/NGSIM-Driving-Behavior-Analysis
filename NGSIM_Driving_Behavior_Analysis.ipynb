{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raswanth-Prasath/NGSIM-Driving-Behavior-Analysis/blob/main/NGSIM_Driving_Behavior_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JZeU7DmNMzO3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import folium\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define column names for the data files\n",
        "column_names = ['Vehicle ID', 'Frame ID', 'Lane ID', 'LocalY', 'Mean Speed', 'Mean Acceleration', 'Vehicle length', 'Vehicle Class ID', 'Follower ID', 'Leader ID']  # replace with actual column names\n",
        "moto_column_names = ['Vehicle ID', 'Frame ID', 'Lane ID', 'LocalY', 'Mean Speed', 'Mean Acceleration', 'Vehicle length', 'Vehicle Class ID']  # replace with actual column names\n",
        "\n",
        "# Read DATA.txt (adjust delimiter if needed)\n",
        "data = pd.read_csv(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\DATA (NO MOTORCYCLES).txt\", delimiter=r\"\\s+\", header=None, names=column_names)  # \\s+ for multiple spaces\n",
        "motorcycles = pd.read_csv(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\MOTORCYCLES.txt\", delimiter=r\"\\s+\", header=None, names=moto_column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.to_csv(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\DATA.csv\", index=False)\n",
        "motorcycles.to_csv(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\MOTORCYCLES.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add missing columns to motorcycles (Leader ID, Follower ID)\n",
        "motorcycles[\"Follower ID\"] = -1\n",
        "motorcycles[\"Leader ID\"] = -1\n",
        "\n",
        "# Combine datasets\n",
        "combined = pd.concat([data, motorcycles], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2029 valid car-following pairs\n",
            "\n",
            "Pair 1:\n",
            "Leader ID: 47.0\n",
            "Follower ID: 64.0\n",
            "Duration: 21.8 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 52.44\n",
            "  std: 18.54\n",
            "  min: 35.11\n",
            "  max: 99.71\n",
            "\n",
            "speed_difference:\n",
            "  mean: 2.83\n",
            "  std: 2.71\n",
            "  min: -1.43\n",
            "  max: 8.23\n",
            "\n",
            "time_headway:\n",
            "  mean: 4.71\n",
            "  std: 1.17\n",
            "  min: 3.39\n",
            "  max: 8.14\n",
            "\n",
            "Pair 2:\n",
            "Leader ID: 2142.0\n",
            "Follower ID: 2153.0\n",
            "Duration: 20.5 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 66.29\n",
            "  std: 15.14\n",
            "  min: 45.03\n",
            "  max: 99.59\n",
            "\n",
            "speed_difference:\n",
            "  mean: 2.67\n",
            "  std: 1.95\n",
            "  min: -0.61\n",
            "  max: 6.10\n",
            "\n",
            "time_headway:\n",
            "  mean: 4.73\n",
            "  std: 1.42\n",
            "  min: 2.75\n",
            "  max: 8.12\n",
            "\n",
            "Pair 3:\n",
            "Leader ID: 2.0\n",
            "Follower ID: 17.0\n",
            "Duration: 26.0 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 36.46\n",
            "  std: 10.12\n",
            "  min: 19.77\n",
            "  max: 57.29\n",
            "\n",
            "speed_difference:\n",
            "  mean: 1.36\n",
            "  std: 1.29\n",
            "  min: -1.81\n",
            "  max: 4.81\n",
            "\n",
            "time_headway:\n",
            "  mean: 2.82\n",
            "  std: 0.35\n",
            "  min: 2.17\n",
            "  max: 4.07\n",
            "\n",
            "Pair 4:\n",
            "Leader ID: 17.0\n",
            "Follower ID: 25.0\n",
            "Duration: 25.7 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 36.95\n",
            "  std: 10.31\n",
            "  min: 21.97\n",
            "  max: 50.71\n",
            "\n",
            "speed_difference:\n",
            "  mean: 0.87\n",
            "  std: 1.44\n",
            "  min: -4.18\n",
            "  max: 3.02\n",
            "\n",
            "time_headway:\n",
            "  mean: 2.71\n",
            "  std: 0.21\n",
            "  min: 2.12\n",
            "  max: 3.25\n",
            "\n",
            "Pair 5:\n",
            "Leader ID: 25.0\n",
            "Follower ID: 39.0\n",
            "Duration: 25.9 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 31.29\n",
            "  std: 7.29\n",
            "  min: 21.87\n",
            "  max: 41.43\n",
            "\n",
            "speed_difference:\n",
            "  mean: 0.63\n",
            "  std: 1.08\n",
            "  min: -1.99\n",
            "  max: 2.43\n",
            "\n",
            "time_headway:\n",
            "  mean: 2.28\n",
            "  std: 0.19\n",
            "  min: 1.92\n",
            "  max: 3.14\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Dict, Tuple\n",
        "\n",
        "@dataclass\n",
        "class CarFollowingPair:\n",
        "    \"\"\"\n",
        "    Represents a validated car-following pair with all relevant information\n",
        "    \"\"\"\n",
        "    leader_id: int\n",
        "    follower_id: int\n",
        "    start_frame: int\n",
        "    end_frame: int\n",
        "    lane_id: int\n",
        "    metrics: Dict = None\n",
        "\n",
        "    @property\n",
        "    def duration(self) -> float:\n",
        "        \"\"\"Duration of car-following episode in seconds\"\"\"\n",
        "        return (self.end_frame - self.start_frame + 1) * 0.1  # Convert frames to seconds\n",
        "\n",
        "class CarFollowingIdentifier:\n",
        "    \"\"\"\n",
        "    Identifies and validates car-following pairs in trajectory data\n",
        "    \"\"\"\n",
        "    def __init__(self, min_duration: float = 20.0,\n",
        "                 min_spacing: float = 2.0,\n",
        "                 max_spacing: float = 100.0):\n",
        "        \"\"\"\n",
        "        Initialize with validation criteria\n",
        "        \n",
        "        Parameters:\n",
        "        min_duration: Minimum duration in seconds for valid car-following\n",
        "        min_spacing: Minimum allowed spacing between vehicles (meters)\n",
        "        max_spacing: Maximum allowed spacing between vehicles (meters)\n",
        "        \"\"\"\n",
        "        self.min_duration = min_duration\n",
        "        self.min_frames = int(min_duration * 10)  # Convert to frames (0.1s intervals)\n",
        "        self.min_spacing = min_spacing\n",
        "        self.max_spacing = max_spacing\n",
        "        \n",
        "    def identify_pairs(self, df: pd.DataFrame) -> List[CarFollowingPair]:\n",
        "        \"\"\"\n",
        "        Main method to identify valid car-following pairs\n",
        "        \n",
        "        Parameters:\n",
        "        df: DataFrame with columns for Vehicle_ID, Frame_ID, Lane_ID, LocalY\n",
        "        \n",
        "        Returns:\n",
        "        List of validated CarFollowingPair objects\n",
        "        \"\"\"\n",
        "        valid_pairs = []\n",
        "        \n",
        "        # Step 1: Group data by lane\n",
        "        for lane_id, lane_data in df.groupby('Lane_ID'):\n",
        "            # Skip special lanes (like merge lanes or shoulders)\n",
        "            if lane_id > 6:  # Assuming regular lanes are 1-6\n",
        "                continue\n",
        "                \n",
        "            # Step 2: Process each time window in the lane\n",
        "            frames = sorted(lane_data['Frame_ID'].unique())\n",
        "            \n",
        "            # Step 3: For each frame, identify potential pairs\n",
        "            current_pairs = {}  # Track ongoing pairs\n",
        "            \n",
        "            for frame in frames:\n",
        "                frame_data = lane_data[lane_data['Frame_ID'] == frame]\n",
        "                \n",
        "                # Sort vehicles by position to identify leader-follower relationships\n",
        "                frame_vehicles = frame_data.sort_values('LocalY', ascending=False)\n",
        "                \n",
        "                # Step 4: Check each consecutive pair of vehicles\n",
        "                for i in range(len(frame_vehicles) - 1):\n",
        "                    leader = frame_vehicles.iloc[i]\n",
        "                    follower = frame_vehicles.iloc[i + 1]\n",
        "                    \n",
        "                    pair_id = (leader['Vehicle_ID'], follower['Vehicle_ID'])\n",
        "                    \n",
        "                    # Calculate spacing\n",
        "                    spacing = leader['LocalY'] - follower['LocalY']\n",
        "                    \n",
        "                    # Validate spacing\n",
        "                    if self.min_spacing <= spacing <= self.max_spacing:\n",
        "                        if pair_id not in current_pairs:\n",
        "                            # Start new pair tracking\n",
        "                            current_pairs[pair_id] = {\n",
        "                                'start_frame': frame,\n",
        "                                'current_frame': frame,\n",
        "                                'lane_id': lane_id\n",
        "                            }\n",
        "                        else:\n",
        "                            # Update existing pair\n",
        "                            current_pairs[pair_id]['current_frame'] = frame\n",
        "                    else:\n",
        "                        # Invalid spacing - end pair if exists\n",
        "                        self._check_and_add_pair(current_pairs, pair_id, valid_pairs)\n",
        "            \n",
        "            # Process any remaining pairs\n",
        "            for pair_id in list(current_pairs.keys()):\n",
        "                self._check_and_add_pair(current_pairs, pair_id, valid_pairs)\n",
        "        \n",
        "        return valid_pairs\n",
        "    \n",
        "    def _check_and_add_pair(self, current_pairs: Dict, \n",
        "                           pair_id: Tuple[int, int],\n",
        "                           valid_pairs: List[CarFollowingPair]) -> None:\n",
        "        \"\"\"\n",
        "        Validates and adds a car-following pair if it meets duration criteria\n",
        "        \"\"\"\n",
        "        if pair_id in current_pairs:\n",
        "            pair_data = current_pairs[pair_id]\n",
        "            duration_frames = pair_data['current_frame'] - pair_data['start_frame'] + 1\n",
        "            \n",
        "            if duration_frames >= self.min_frames:\n",
        "                # Create validated pair\n",
        "                valid_pairs.append(CarFollowingPair(\n",
        "                    leader_id=pair_id[0],\n",
        "                    follower_id=pair_id[1],\n",
        "                    start_frame=pair_data['start_frame'],\n",
        "                    end_frame=pair_data['current_frame'],\n",
        "                    lane_id=pair_data['lane_id']\n",
        "                ))\n",
        "            \n",
        "            # Remove pair from tracking\n",
        "            del current_pairs[pair_id]\n",
        "    \n",
        "    def compute_pair_metrics(self, pair: CarFollowingPair, \n",
        "                           df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"\n",
        "        Computes detailed metrics for a validated car-following pair\n",
        "        \n",
        "        Parameters:\n",
        "        pair: CarFollowingPair object\n",
        "        df: Original trajectory DataFrame\n",
        "        \n",
        "        Returns:\n",
        "        Dictionary of computed metrics\n",
        "        \"\"\"\n",
        "        # Get leader and follower trajectories\n",
        "        leader_data = df[(df['Vehicle_ID'] == pair.leader_id) & \n",
        "                        (df['Frame_ID'] >= pair.start_frame) & \n",
        "                        (df['Frame_ID'] <= pair.end_frame)]\n",
        "        \n",
        "        follower_data = df[(df['Vehicle_ID'] == pair.follower_id) & \n",
        "                          (df['Frame_ID'] >= pair.start_frame) & \n",
        "                          (df['Frame_ID'] <= pair.end_frame)]\n",
        "        \n",
        "        # Compute spacing statistics\n",
        "        spacing = leader_data['LocalY'].values - follower_data['LocalY'].values\n",
        "        \n",
        "        # Compute speed difference statistics\n",
        "        speed_diff = leader_data['Speed'].values - follower_data['Speed'].values\n",
        "        \n",
        "        # Compute time headway\n",
        "        time_headway = spacing / follower_data['Speed'].values\n",
        "        valid_headway = time_headway[~np.isinf(time_headway)]\n",
        "        \n",
        "        return {\n",
        "            'spacing': {\n",
        "                'mean': np.mean(spacing),\n",
        "                'std': np.std(spacing),\n",
        "                'min': np.min(spacing),\n",
        "                'max': np.max(spacing)\n",
        "            },\n",
        "            'speed_difference': {\n",
        "                'mean': np.mean(speed_diff),\n",
        "                'std': np.std(speed_diff),\n",
        "                'min': np.min(speed_diff),\n",
        "                'max': np.max(speed_diff)\n",
        "            },\n",
        "            'time_headway': {\n",
        "                'mean': np.mean(valid_headway),\n",
        "                'std': np.std(valid_headway),\n",
        "                'min': np.min(valid_headway),\n",
        "                'max': np.max(valid_headway)\n",
        "            }\n",
        "        }\n",
        "\n",
        "def main():\n",
        "    # Example usage\n",
        "    # Read the data file\n",
        "    df = pd.read_csv(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\DATA (NO MOTORCYCLES).txt\", delimiter='\\s+', header=None,\n",
        "                     names=['Vehicle_ID', 'Frame_ID', 'Lane_ID', 'LocalY',\n",
        "                           'Speed', 'Acceleration', 'Vehicle_Length',\n",
        "                           'Vehicle_Class', 'Follower_ID', 'Leader_ID'])\n",
        "    \n",
        "    # Initialize identifier\n",
        "    identifier = CarFollowingIdentifier(\n",
        "        min_duration=20.0,  # 20 seconds minimum\n",
        "        min_spacing=2.0,    # 2 meters minimum spacing\n",
        "        max_spacing=100.0   # 100 meters maximum spacing\n",
        "    )\n",
        "    \n",
        "    # Find car-following pairs\n",
        "    pairs = identifier.identify_pairs(df)\n",
        "    \n",
        "    # Print summary\n",
        "    print(f\"Found {len(pairs)} valid car-following pairs\")\n",
        "    \n",
        "    # Analyze first few pairs\n",
        "    for i, pair in enumerate(pairs[:5]):\n",
        "        print(f\"\\nPair {i+1}:\")\n",
        "        print(f\"Leader ID: {pair.leader_id}\")\n",
        "        print(f\"Follower ID: {pair.follower_id}\")\n",
        "        print(f\"Duration: {pair.duration:.1f} seconds\")\n",
        "        print(f\"Lane: {pair.lane_id}\")\n",
        "        \n",
        "        # Compute and print metrics\n",
        "        metrics = identifier.compute_pair_metrics(pair, df)\n",
        "        print(\"\\nMetrics:\")\n",
        "        for metric, values in metrics.items():\n",
        "            print(f\"\\n{metric}:\")\n",
        "            for stat, value in values.items():\n",
        "                print(f\"  {stat}: {value:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyzes statistical properties of car-following pairs and generates comprehensive visualizations and analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Car-Following Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-06 13:44:25,758 - __main__ - INFO - Loading data...\n",
            "2025-02-06 13:44:25,758 - __main__ - INFO - Loading data...\n",
            "2025-02-06 13:44:25,758 - __main__ - INFO - Loading data...\n",
            "2025-02-06 13:44:25,758 - __main__ - INFO - Loading data...\n",
            "INFO:__main__:Loading data...\n",
            "2025-02-06 13:44:28,439 - __main__ - INFO - Successfully loaded data with 1055801 rows\n",
            "2025-02-06 13:44:28,439 - __main__ - INFO - Successfully loaded data with 1055801 rows\n",
            "2025-02-06 13:44:28,439 - __main__ - INFO - Successfully loaded data with 1055801 rows\n",
            "2025-02-06 13:44:28,439 - __main__ - INFO - Successfully loaded data with 1055801 rows\n",
            "INFO:__main__:Successfully loaded data with 1055801 rows\n",
            "2025-02-06 13:44:28,442 - __main__ - INFO - Finding car-following pairs...\n",
            "2025-02-06 13:44:28,442 - __main__ - INFO - Finding car-following pairs...\n",
            "2025-02-06 13:44:28,442 - __main__ - INFO - Finding car-following pairs...\n",
            "2025-02-06 13:44:28,442 - __main__ - INFO - Finding car-following pairs...\n",
            "INFO:__main__:Finding car-following pairs...\n",
            "2025-02-06 13:44:33,745 - __main__ - INFO - Found 2056 car-following pairs\n",
            "2025-02-06 13:44:33,745 - __main__ - INFO - Found 2056 car-following pairs\n",
            "2025-02-06 13:44:33,745 - __main__ - INFO - Found 2056 car-following pairs\n",
            "2025-02-06 13:44:33,745 - __main__ - INFO - Found 2056 car-following pairs\n",
            "INFO:__main__:Found 2056 car-following pairs\n",
            "2025-02-06 13:44:33,754 - __main__ - INFO - Processing and visualizing selected pairs...\n",
            "2025-02-06 13:44:33,754 - __main__ - INFO - Processing and visualizing selected pairs...\n",
            "2025-02-06 13:44:33,754 - __main__ - INFO - Processing and visualizing selected pairs...\n",
            "2025-02-06 13:44:33,754 - __main__ - INFO - Processing and visualizing selected pairs...\n",
            "INFO:__main__:Processing and visualizing selected pairs...\n",
            "2025-02-06 13:44:42,264 - __main__ - INFO - Analysis complete!\n",
            "2025-02-06 13:44:42,264 - __main__ - INFO - Analysis complete!\n",
            "2025-02-06 13:44:42,264 - __main__ - INFO - Analysis complete!\n",
            "2025-02-06 13:44:42,264 - __main__ - INFO - Analysis complete!\n",
            "INFO:__main__:Analysis complete!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "\n",
        "# Configure logger\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "handler = logging.StreamHandler()\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load and process the trajectory data\"\"\"\n",
        "    try:\n",
        "        # Read data with numbered columns first\n",
        "        data = pd.read_csv(file_path, delimiter='\\s+', header=None)\n",
        "        \n",
        "        # Rename columns to match expected format\n",
        "        data.columns = ['Vehicle_ID', 'Frame_ID', 'Lane_ID', 'Local_Y', \n",
        "                       'Speed', 'Acceleration', 'Vehicle_Length',\n",
        "                       'Vehicle_Class', 'Follower_ID', 'Leader_ID']\n",
        "        \n",
        "        logger.info(f\"Successfully loaded data with {len(data)} rows\")\n",
        "        return data\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading data: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def find_car_following_pairs(data):\n",
        "    \"\"\"Identify car-following pairs that persist for at least 20 seconds\"\"\"\n",
        "    pairs = []\n",
        "    min_duration = 200  # 20 seconds (at 0.1s intervals)\n",
        "    \n",
        "    # Process each vehicle\n",
        "    for vehicle_id in data['Vehicle_ID'].unique():\n",
        "        vehicle_data = data[data['Vehicle_ID'] == vehicle_id].sort_values('Frame_ID')\n",
        "        \n",
        "        # Find unique leaders (excluding -1 which indicates no leader)\n",
        "        leaders = vehicle_data['Leader_ID'].unique()\n",
        "        leaders = leaders[leaders != -1]\n",
        "        \n",
        "        for leader_id in leaders:\n",
        "            # Get frames where this vehicle follows the current leader\n",
        "            following_frames = vehicle_data[vehicle_data['Leader_ID'] == leader_id]['Frame_ID']\n",
        "            \n",
        "            if len(following_frames) >= min_duration:\n",
        "                pairs.append({\n",
        "                    'leader_id': leader_id,\n",
        "                    'follower_id': vehicle_id,\n",
        "                    'start_frame': following_frames.iloc[0],\n",
        "                    'end_frame': following_frames.iloc[-1],\n",
        "                    'lane': vehicle_data['Lane_ID'].iloc[0],\n",
        "                    'duration': len(following_frames) * 0.1  # Convert to seconds\n",
        "                })\n",
        "    \n",
        "    logger.info(f\"Found {len(pairs)} car-following pairs\")\n",
        "    return pairs\n",
        "\n",
        "def process_pair_data(data, selected_pairs):\n",
        "    \"\"\"Process data for selected car-following pairs\"\"\"\n",
        "    pair_data = []\n",
        "    \n",
        "    for pair in selected_pairs:\n",
        "        # Get trajectory data for leader and follower\n",
        "        frames = range(int(pair['start_frame']), int(pair['end_frame']) + 1)\n",
        "        \n",
        "        leader_data = data[\n",
        "            (data['Vehicle_ID'] == pair['leader_id']) & \n",
        "            (data['Frame_ID'].isin(frames))\n",
        "        ].sort_values('Frame_ID')\n",
        "        \n",
        "        follower_data = data[\n",
        "            (data['Vehicle_ID'] == pair['follower_id']) & \n",
        "            (data['Frame_ID'].isin(frames))\n",
        "        ].sort_values('Frame_ID')\n",
        "        \n",
        "        # Combine data\n",
        "        merged_data = pd.merge(\n",
        "            leader_data, \n",
        "            follower_data,\n",
        "            on='Frame_ID',\n",
        "            suffixes=('_leader', '_follower')\n",
        "        )\n",
        "        \n",
        "        time_data = []\n",
        "        for _, row in merged_data.iterrows():\n",
        "            time_data.append({\n",
        "                'time': (row['Frame_ID'] - pair['start_frame']) * 0.1,\n",
        "                'leader_speed': row['Speed_leader'],\n",
        "                'follower_speed': row['Speed_follower'],\n",
        "                'spacing': row['Local_Y_leader'] - row['Local_Y_follower'],\n",
        "                'relative_speed': row['Speed_leader'] - row['Speed_follower']\n",
        "            })\n",
        "        \n",
        "        pair_data.append({\n",
        "            'pair_id': f\"{pair['leader_id']}-{pair['follower_id']}\",\n",
        "            'time_data': pd.DataFrame(time_data)\n",
        "        })\n",
        "    \n",
        "    return pair_data\n",
        "\n",
        "def plot_pair_visualizations(pair_data):\n",
        "    \"\"\"Create visualizations for car-following pairs\"\"\"\n",
        "    for pair in pair_data:\n",
        "        time_data = pair['time_data']\n",
        "        \n",
        "        fig, axes = plt.subplots(3, 1, figsize=(12, 15))\n",
        "        fig.suptitle(f\"Car-Following Pair Analysis\\nPair {pair['pair_id']}\")\n",
        "        \n",
        "        # Speed profiles\n",
        "        axes[0].plot(time_data['time'], time_data['leader_speed'], \n",
        "                    label='Leader', color='blue', linewidth=2)\n",
        "        axes[0].plot(time_data['time'], time_data['follower_speed'], \n",
        "                    label='Follower', color='red', linestyle='--', linewidth=2)\n",
        "        axes[0].set_xlabel('Time (s)')\n",
        "        axes[0].set_ylabel('Speed (m/s)')\n",
        "        axes[0].set_title('Speed Profiles')\n",
        "        axes[0].grid(True)\n",
        "        axes[0].legend()\n",
        "        \n",
        "        # Space gap\n",
        "        axes[1].plot(time_data['time'], time_data['spacing'], \n",
        "                    color='green', linewidth=2)\n",
        "        axes[1].set_xlabel('Time (s)')\n",
        "        axes[1].set_ylabel('Space Gap (m)')\n",
        "        axes[1].set_title('Following Distance')\n",
        "        axes[1].grid(True)\n",
        "        \n",
        "        # Relative speed\n",
        "        axes[2].plot(time_data['time'], time_data['relative_speed'], \n",
        "                    color='purple', linewidth=2)\n",
        "        axes[2].set_xlabel('Time (s)')\n",
        "        axes[2].set_ylabel('Relative Speed (m/s)')\n",
        "        axes[2].set_title('Relative Speed (Leader - Follower)')\n",
        "        axes[2].grid(True)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        stats_text = (\n",
        "            f\"Mean Space Gap: {time_data['spacing'].mean():.1f}m\\n\"\n",
        "            f\"Mean Relative Speed: {time_data['relative_speed'].mean():.2f}m/s\\n\"\n",
        "            f\"Duration: {len(time_data)*0.1:.1f}s\"\n",
        "        )\n",
        "        plt.figtext(0.02, 0.02, stats_text, fontsize=10, \n",
        "                   bbox=dict(facecolor='white', alpha=0.8))\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'pair_{pair[\"pair_id\"]}_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    logger.info(\"Loading data...\")\n",
        "    data = load_data(\"D:/ASU Academics/Traffic Flow Theroy/MP-1/Reconstructed NGSIM I80-1 data/Data/DATA (NO MOTORCYCLES).txt\")\n",
        "    \n",
        "    if len(data) == 0:\n",
        "        logger.error(\"Failed to load data\")\n",
        "        return\n",
        "        \n",
        "    # Find car-following pairs\n",
        "    logger.info(\"Finding car-following pairs...\")\n",
        "    pairs = find_car_following_pairs(data)\n",
        "    \n",
        "    if len(pairs) == 0:\n",
        "        logger.error(\"No car-following pairs found\")\n",
        "        return\n",
        "        \n",
        "    # Select first 5 pairs\n",
        "    selected_pairs = pairs[:5]\n",
        "    \n",
        "    # Process and visualize pairs\n",
        "    logger.info(\"Processing and visualizing selected pairs...\")\n",
        "    pair_data = process_pair_data(data, selected_pairs)\n",
        "    plot_pair_visualizations(pair_data)\n",
        "    \n",
        "    logger.info(\"Analysis complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Lane Change Analysis :** Count the lane-change occurrences in the dataset. Analyze where and when these lane changes occur, identifying any observable trends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading data file...\n",
            "Analyzing lane changes...\n",
            "Generating statistics...\n",
            "\n",
            "Lane Change Analysis Summary:\n",
            "Total lane changes: 164\n",
            "\n",
            "Direction distribution:\n",
            "right: 140 (85.4%)\n",
            "left: 24 (14.6%)\n",
            "\n",
            "Average duration: 15.44 seconds\n",
            "\n",
            "Speed statistics during lane changes:\n",
            "mean: 7.95 m/s\n",
            "std: 2.52 m/s\n",
            "min: 1.82 m/s\n",
            "max: 14.77 m/s\n",
            "\n",
            "Creating visualizations...\n",
            "Analysis complete. Visualizations saved as 'lane_change_analysis.png'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "class LaneChangeAnalyzer:\n",
        "    def __init__(self, min_duration: float = 0.5):\n",
        "        self.min_duration = min_duration\n",
        "        self.min_frames = int(min_duration * 10)\n",
        "        self.lane_changes = []\n",
        "        \n",
        "    def analyze_trajectories(self, df: pd.DataFrame) -> None:\n",
        "        \"\"\"Analyzes trajectory data to identify lane changes\"\"\"\n",
        "        # First, rename columns to match our expected format\n",
        "        df.columns = ['Vehicle_ID', 'Frame_ID', 'Lane_ID', 'LocalY',\n",
        "                     'Speed', 'Acceleration', 'Vehicle_Length',\n",
        "                     'Vehicle_Class', 'Follower_ID', 'Leader_ID']\n",
        "        \n",
        "        # Group by vehicle\n",
        "        for vehicle_id in df['Vehicle_ID'].unique():\n",
        "            # Get vehicle's trajectory\n",
        "            vehicle_data = df[df['Vehicle_ID'] == vehicle_id].sort_values('Frame_ID')\n",
        "            \n",
        "            # Initialize variables for tracking lane changes\n",
        "            prev_lane = None\n",
        "            start_frame = None\n",
        "            from_lane = None\n",
        "            \n",
        "            # Analyze frame by frame\n",
        "            for idx, row in vehicle_data.iterrows():\n",
        "                curr_lane = row['Lane_ID']\n",
        "                \n",
        "                if prev_lane is not None and curr_lane != prev_lane:\n",
        "                    if start_frame is None:\n",
        "                        # Start of lane change\n",
        "                        start_frame = row['Frame_ID']\n",
        "                        from_lane = prev_lane\n",
        "                    elif curr_lane != from_lane:\n",
        "                        # End of lane change\n",
        "                        end_frame = row['Frame_ID']\n",
        "                        duration = (end_frame - start_frame) * 0.1\n",
        "                        \n",
        "                        if duration >= self.min_duration:\n",
        "                            self.lane_changes.append({\n",
        "                                'vehicle_id': vehicle_id,\n",
        "                                'start_frame': start_frame,\n",
        "                                'end_frame': end_frame,\n",
        "                                'from_lane': from_lane,\n",
        "                                'to_lane': curr_lane,\n",
        "                                'position': row['LocalY'],\n",
        "                                'speed': row['Speed'],\n",
        "                                'duration': duration,\n",
        "                                'direction': 'left' if curr_lane > from_lane else 'right'\n",
        "                            })\n",
        "                        \n",
        "                        # Reset for next lane change\n",
        "                        start_frame = None\n",
        "                        from_lane = None\n",
        "                \n",
        "                prev_lane = curr_lane\n",
        "    \n",
        "    def generate_statistics(self) -> dict:\n",
        "        \"\"\"Generates summary statistics of lane changes\"\"\"\n",
        "        if not self.lane_changes:\n",
        "            return {\n",
        "                'total_changes': 0,\n",
        "                'direction_counts': {'left': 0, 'right': 0},\n",
        "                'avg_duration': 0,\n",
        "                'speed_stats': {'mean': 0, 'std': 0, 'min': 0, 'max': 0}\n",
        "            }\n",
        "            \n",
        "        df_changes = pd.DataFrame(self.lane_changes)\n",
        "        \n",
        "        stats = {\n",
        "            'total_changes': len(self.lane_changes),\n",
        "            'direction_counts': df_changes['direction'].value_counts().to_dict(),\n",
        "            'avg_duration': df_changes['duration'].mean(),\n",
        "            'speed_stats': {\n",
        "                'mean': df_changes['speed'].mean(),\n",
        "                'std': df_changes['speed'].std(),\n",
        "                'min': df_changes['speed'].min(),\n",
        "                'max': df_changes['speed'].max()\n",
        "            },\n",
        "            'lane_transitions': pd.crosstab(\n",
        "                df_changes['from_lane'],\n",
        "                df_changes['to_lane']\n",
        "            ).to_dict(),\n",
        "            'position_dist': pd.cut(\n",
        "                df_changes['position'],\n",
        "                bins=np.arange(0, df_changes['position'].max() + 100, 100)\n",
        "            ).value_counts().sort_index().to_dict()\n",
        "        }\n",
        "        \n",
        "        return stats\n",
        "    \n",
        "    def plot_analysis(self, stats: dict) -> None:\n",
        "        \"\"\"Creates visualizations of lane change patterns\"\"\"\n",
        "        fig = plt.figure(figsize=(15, 10))\n",
        "        \n",
        "        # 1. Direction Distribution (Top Left)\n",
        "        plt.subplot(221)\n",
        "        directions = list(stats['direction_counts'].keys())\n",
        "        counts = list(stats['direction_counts'].values())\n",
        "        plt.bar(directions, counts)\n",
        "        plt.title('Lane Change Direction Distribution')\n",
        "        plt.ylabel('Number of Lane Changes')\n",
        "        \n",
        "        # 2. Position Distribution (Top Right)\n",
        "        plt.subplot(222)\n",
        "        positions = list(stats['position_dist'].keys())\n",
        "        position_counts = list(stats['position_dist'].values())\n",
        "        plt.bar(range(len(positions)), position_counts)\n",
        "        plt.title('Lane Change Position Distribution')\n",
        "        plt.xlabel('Position (100m segments)')\n",
        "        plt.ylabel('Number of Lane Changes')\n",
        "        \n",
        "        # 3. Lane Transitions Heatmap (Bottom Left)\n",
        "        plt.subplot(223)\n",
        "        if self.lane_changes:\n",
        "            df_changes = pd.DataFrame(self.lane_changes)\n",
        "            transition_matrix = pd.crosstab(\n",
        "                df_changes['from_lane'],\n",
        "                df_changes['to_lane']\n",
        "            )\n",
        "            sns.heatmap(transition_matrix, annot=True, fmt='d', cmap='YlOrRd')\n",
        "            plt.title('Lane Change Transitions')\n",
        "            plt.xlabel('To Lane')\n",
        "            plt.ylabel('From Lane')\n",
        "                    \n",
        "        # 4. Speed Distribution (Bottom Right)\n",
        "        plt.subplot(224)\n",
        "        if self.lane_changes:\n",
        "            speeds = [lc['speed'] for lc in self.lane_changes]\n",
        "            plt.hist(speeds, bins=20)\n",
        "            plt.title('Speed During Lane Changes')\n",
        "            plt.xlabel('Speed (m/s)')\n",
        "            plt.ylabel('Frequency')\n",
        "                    \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('lane_change_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "def main():\n",
        "    # Read data file\n",
        "    print(\"Reading data file...\")\n",
        "    df = pd.read_csv(\"D:/ASU Academics/Traffic Flow Theroy/MP-1/Reconstructed NGSIM I80-1 data/Data/DATA (NO MOTORCYCLES).txt\", delimiter='\\s+', header=None)\n",
        "    \n",
        "    # Initialize analyzer\n",
        "    print(\"Analyzing lane changes...\")\n",
        "    analyzer = LaneChangeAnalyzer(min_duration=0.5)\n",
        "    \n",
        "    # Analyze trajectories\n",
        "    analyzer.analyze_trajectories(df)\n",
        "    \n",
        "    # Generate statistics\n",
        "    print(\"Generating statistics...\")\n",
        "    stats = analyzer.generate_statistics()\n",
        "    \n",
        "    # Print summary\n",
        "    print(\"\\nLane Change Analysis Summary:\")\n",
        "    print(f\"Total lane changes: {stats['total_changes']}\")\n",
        "    print(\"\\nDirection distribution:\")\n",
        "    for direction, count in stats['direction_counts'].items():\n",
        "        print(f\"{direction}: {count} ({count/stats['total_changes']*100:.1f}%)\")\n",
        "    print(f\"\\nAverage duration: {stats['avg_duration']:.2f} seconds\")\n",
        "    print(\"\\nSpeed statistics during lane changes:\")\n",
        "    for stat, value in stats['speed_stats'].items():\n",
        "        print(f\"{stat}: {value:.2f} m/s\")\n",
        "    \n",
        "    # Create visualizations\n",
        "    print(\"\\nCreating visualizations...\")\n",
        "    analyzer.plot_analysis(stats)\n",
        "    print(\"Analysis complete. Visualizations saved as 'lane_change_analysis.png'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Time-Space Diagram :** Plot the lane-by-lane time-space diagram for all the NGSIM trajectory data. Based on the diagram, discuss traffic conditions and patterns of congestion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating time-space diagrams...\n",
            "Creating congestion heatmap...\n",
            "\n",
            "Analyzing congestion patterns...\n",
            "\n",
            "Traffic Analysis Summary:\n",
            "\n",
            "Congestion threshold: 10 m/s\n",
            "\n",
            "Lane Statistics:\n",
            "          mean   std   min    max\n",
            "Lane_ID                          \n",
            "1        16.63  3.71  0.58  31.63\n",
            "2         7.11  2.64  0.00  17.74\n",
            "3         7.06  2.47  0.00  16.52\n",
            "4         6.37  2.78  0.00  16.74\n",
            "5         7.02  2.99  0.00  19.24\n",
            "6         6.90  3.14  0.00  20.08\n",
            "7         6.34  4.18  0.00  20.74\n",
            "999      10.76  3.60  0.80  17.77\n",
            "\n",
            "Congestion Periods:\n",
            "Lane 2: Time window (0.0, 300.0], Average speed: 7.3 m/s\n",
            "Lane 2: Time window (300.0, 600.0], Average speed: 7.5 m/s\n",
            "Lane 2: Time window (600.0, 900.0], Average speed: 6.3 m/s\n",
            "Lane 2: Time window (900.0, 1200.0], Average speed: 9.1 m/s\n",
            "Lane 3: Time window (0.0, 300.0], Average speed: 7.6 m/s\n",
            "Lane 3: Time window (300.0, 600.0], Average speed: 7.1 m/s\n",
            "Lane 3: Time window (600.0, 900.0], Average speed: 6.4 m/s\n",
            "Lane 3: Time window (900.0, 1200.0], Average speed: 8.2 m/s\n",
            "Lane 4: Time window (0.0, 300.0], Average speed: 7.5 m/s\n",
            "Lane 4: Time window (300.0, 600.0], Average speed: 7.0 m/s\n",
            "Lane 4: Time window (600.0, 900.0], Average speed: 5.0 m/s\n",
            "Lane 4: Time window (900.0, 1200.0], Average speed: 7.5 m/s\n",
            "Lane 5: Time window (0.0, 300.0], Average speed: 8.0 m/s\n",
            "Lane 5: Time window (300.0, 600.0], Average speed: 8.4 m/s\n",
            "Lane 5: Time window (600.0, 900.0], Average speed: 5.4 m/s\n",
            "Lane 5: Time window (900.0, 1200.0], Average speed: 7.0 m/s\n",
            "Lane 6: Time window (0.0, 300.0], Average speed: 7.2 m/s\n",
            "Lane 6: Time window (300.0, 600.0], Average speed: 8.1 m/s\n",
            "Lane 6: Time window (600.0, 900.0], Average speed: 5.9 m/s\n",
            "Lane 6: Time window (900.0, 1200.0], Average speed: 6.5 m/s\n",
            "Lane 7: Time window (0.0, 300.0], Average speed: 8.1 m/s\n",
            "Lane 7: Time window (300.0, 600.0], Average speed: 7.6 m/s\n",
            "Lane 7: Time window (600.0, 900.0], Average speed: 4.9 m/s\n",
            "Lane 7: Time window (900.0, 1200.0], Average speed: 5.1 m/s\n",
            "Lane 999: Time window (300.0, 600.0], Average speed: 5.2 m/s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Raswanth\\AppData\\Local\\Temp\\ipykernel_70352\\1134846835.py:129: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  speed_stats = self.df.groupby(['Lane_ID', 'time_window'])['Speed'].agg([\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.collections import LineCollection\n",
        "import seaborn as sns\n",
        "\n",
        "class TimeSpaceDiagramAnalyzer:\n",
        "    def __init__(self, data_file: str):\n",
        "        \"\"\"Initialize analyzer with data file path\"\"\"\n",
        "        self.df = pd.read_csv(data_file, delimiter='\\s+', header=None,\n",
        "                             names=['Vehicle_ID', 'Frame_ID', 'Lane_ID', 'LocalY',\n",
        "                                   'Speed', 'Acceleration', 'Vehicle_Length',\n",
        "                                   'Vehicle_Class', 'Follower_ID', 'Leader_ID'])\n",
        "        \n",
        "        # Convert Frame_ID to time in seconds\n",
        "        self.df['Time'] = self.df['Frame_ID'] * 0.1\n",
        "        \n",
        "    def plot_lane_diagram(self, lane_id: int, ax=None, cmap='viridis'):\n",
        "        \"\"\"Plot time-space diagram for a specific lane\"\"\"\n",
        "        lane_data = self.df[self.df['Lane_ID'] == lane_id]\n",
        "        \n",
        "        lines = []\n",
        "        colors = []\n",
        "        \n",
        "        for vehicle_id in lane_data['Vehicle_ID'].unique():\n",
        "            vehicle_traj = lane_data[lane_data['Vehicle_ID'] == vehicle_id]\n",
        "            if len(vehicle_traj) > 1:\n",
        "                points = np.column_stack((vehicle_traj['Time'], \n",
        "                                       vehicle_traj['LocalY']))\n",
        "                lines.append(points)\n",
        "                colors.append(np.mean(vehicle_traj['Speed']))\n",
        "        \n",
        "        if not lines:\n",
        "            return None\n",
        "            \n",
        "        lc = LineCollection(lines, cmap=plt.get_cmap(cmap))\n",
        "        lc.set_array(np.array(colors))\n",
        "        \n",
        "        if ax is None:\n",
        "            ax = plt.gca()\n",
        "            \n",
        "        line = ax.add_collection(lc)\n",
        "        \n",
        "        # Set axis limits\n",
        "        times = lane_data['Time']\n",
        "        positions = lane_data['LocalY']\n",
        "        ax.set_xlim(times.min(), times.max())\n",
        "        ax.set_ylim(positions.min(), positions.max())\n",
        "        \n",
        "        return line\n",
        "\n",
        "    def create_full_diagram(self):\n",
        "        \"\"\"Create time-space diagrams for all lanes\"\"\"\n",
        "        lanes = sorted(self.df['Lane_ID'].unique())\n",
        "        n_lanes = len(lanes)\n",
        "        \n",
        "        fig, axes = plt.subplots(n_lanes, 1, figsize=(15, 4*n_lanes), sharex=True)\n",
        "        if n_lanes == 1:\n",
        "            axes = [axes]\n",
        "            \n",
        "        fig.suptitle('Time-Space Diagram by Lane', fontsize=16, y=0.92)\n",
        "        \n",
        "        for ax, lane_id in zip(axes, lanes):\n",
        "            line = self.plot_lane_diagram(lane_id, ax=ax)\n",
        "            if line is not None:\n",
        "                plt.colorbar(line, ax=ax, label='Speed (m/s)')\n",
        "            \n",
        "            ax.set_ylabel('Position (m)')\n",
        "            ax.set_title(f'Lane {lane_id}')\n",
        "            ax.grid(True, linestyle='--', alpha=0.7)\n",
        "            \n",
        "        axes[-1].set_xlabel('Time (seconds)')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        return fig, axes\n",
        "\n",
        "    def plot_congestion_heatmap(self):\n",
        "        \"\"\"Create a heatmap showing average speeds by lane and time\"\"\"\n",
        "        # Calculate time bins (5-minute intervals)\n",
        "        time_bins = np.arange(0, self.df['Time'].max() + 300, 300)\n",
        "        lanes = sorted(self.df['Lane_ID'].unique())\n",
        "        \n",
        "        # Create speed matrix\n",
        "        speed_matrix = np.zeros((len(lanes), len(time_bins)-1))\n",
        "        \n",
        "        for i, lane_id in enumerate(lanes):\n",
        "            lane_data = self.df[self.df['Lane_ID'] == lane_id]\n",
        "            \n",
        "            for j, (t_start, t_end) in enumerate(zip(time_bins[:-1], time_bins[1:])):\n",
        "                mask = (lane_data['Time'] >= t_start) & (lane_data['Time'] < t_end)\n",
        "                avg_speed = lane_data[mask]['Speed'].mean()\n",
        "                speed_matrix[i, j] = avg_speed if not np.isnan(avg_speed) else 0\n",
        "        \n",
        "        # Create figure\n",
        "        fig, ax = plt.subplots(figsize=(15, 5))\n",
        "        \n",
        "        # Create heatmap\n",
        "        im = ax.imshow(speed_matrix, \n",
        "                      aspect='auto',\n",
        "                      cmap='RdYlGn',\n",
        "                      extent=[0, self.df['Time'].max()/60, len(lanes)-0.5, -0.5])\n",
        "        \n",
        "        # Add colorbar\n",
        "        plt.colorbar(im, ax=ax, label='Average Speed (m/s)')\n",
        "        \n",
        "        # Configure axes\n",
        "        ax.set_yticks(range(len(lanes)))\n",
        "        ax.set_yticklabels([f'Lane {lane}' for lane in lanes])\n",
        "        \n",
        "        # Add time labels (in minutes)\n",
        "        time_ticks = np.linspace(0, self.df['Time'].max()/60, 10)\n",
        "        ax.set_xticks(time_ticks)\n",
        "        ax.set_xticklabels([f'{t:.0f}' for t in time_ticks])\n",
        "        \n",
        "        plt.title('Traffic Speed Heatmap')\n",
        "        plt.xlabel('Time (minutes)')\n",
        "        plt.ylabel('Lane')\n",
        "        \n",
        "        return fig, ax\n",
        "\n",
        "    def analyze_congestion(self):\n",
        "        \"\"\"Analyze congestion patterns\"\"\"\n",
        "        congestion_threshold = 10  # m/s\n",
        "        \n",
        "        # Calculate average speeds in 5-minute windows\n",
        "        self.df['time_window'] = pd.cut(self.df['Time'], \n",
        "                                      bins=np.arange(0, self.df['Time'].max() + 300, 300))\n",
        "        \n",
        "        speed_stats = self.df.groupby(['Lane_ID', 'time_window'])['Speed'].agg([\n",
        "            'mean', 'std', 'count'\n",
        "        ]).reset_index()\n",
        "        \n",
        "        # Identify congestion\n",
        "        congestion = speed_stats[speed_stats['mean'] < congestion_threshold]\n",
        "        \n",
        "        # Calculate overall statistics\n",
        "        lane_stats = self.df.groupby('Lane_ID')['Speed'].agg([\n",
        "            'mean', 'std', 'min', 'max'\n",
        "        ]).round(2)\n",
        "        \n",
        "        return {\n",
        "            'congestion_periods': congestion,\n",
        "            'lane_statistics': lane_stats,\n",
        "            'congestion_threshold': congestion_threshold\n",
        "        }\n",
        "\n",
        "def main():\n",
        "    # Initialize analyzer\n",
        "    analyzer = TimeSpaceDiagramAnalyzer(\"D:/ASU Academics/Traffic Flow Theroy/MP-1/Reconstructed NGSIM I80-1 data/Data/DATA (NO MOTORCYCLES).txt\")\n",
        "    \n",
        "    # Create time-space diagrams\n",
        "    print(\"Creating time-space diagrams...\")\n",
        "    fig_ts, axes_ts = analyzer.create_full_diagram()\n",
        "    fig_ts.savefig('time_space_diagram.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close(fig_ts)\n",
        "    \n",
        "    # Create congestion heatmap\n",
        "    print(\"Creating congestion heatmap...\")\n",
        "    fig_heat, ax_heat = analyzer.plot_congestion_heatmap()\n",
        "    fig_heat.savefig('congestion_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close(fig_heat)\n",
        "    \n",
        "    # Analyze congestion\n",
        "    print(\"\\nAnalyzing congestion patterns...\")\n",
        "    stats = analyzer.analyze_congestion()\n",
        "    \n",
        "    # Print summary\n",
        "    print(\"\\nTraffic Analysis Summary:\")\n",
        "    print(f\"\\nCongestion threshold: {stats['congestion_threshold']} m/s\")\n",
        "    \n",
        "    print(\"\\nLane Statistics:\")\n",
        "    print(stats['lane_statistics'])\n",
        "    \n",
        "    print(\"\\nCongestion Periods:\")\n",
        "    congestion = stats['congestion_periods']\n",
        "    if not congestion.empty:\n",
        "        for _, period in congestion.iterrows():\n",
        "            print(f\"Lane {period['Lane_ID']}: \"\n",
        "                  f\"Time window {period['time_window']}, \"\n",
        "                  f\"Average speed: {period['mean']:.1f} m/s\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM0v56CcdsFMwzTHD8CbcyE",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tdsp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
