{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raswanth-Prasath/NGSIM-Driving-Behavior-Analysis/blob/main/NGSIM_Driving_Behavior_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JZeU7DmNMzO3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import folium\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define column names for the data files\n",
        "column_names = ['Vehicle ID', 'Frame ID', 'Lane ID', 'LocalY', 'Mean Speed', 'Mean Acceleration', 'Vehicle length', 'Vehicle Class ID', 'Follower ID', 'Leader ID']  # replace with actual column names\n",
        "moto_column_names = ['Vehicle ID', 'Frame ID', 'Lane ID', 'LocalY', 'Mean Speed', 'Mean Acceleration', 'Vehicle length', 'Vehicle Class ID']  # replace with actual column names\n",
        "\n",
        "# Read DATA.txt (adjust delimiter if needed)\n",
        "data = pd.read_csv(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\DATA (NO MOTORCYCLES).txt\", delimiter=r\"\\s+\", header=None, names=column_names)  # \\s+ for multiple spaces\n",
        "motorcycles = pd.read_csv(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\MOTORCYCLES.txt\", delimiter=r\"\\s+\", header=None, names=moto_column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.to_csv(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\DATA.csv\", index=False)\n",
        "motorcycles.to_csv(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\MOTORCYCLES.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add missing columns to motorcycles (Leader ID, Follower ID)\n",
        "motorcycles[\"Follower ID\"] = -1\n",
        "motorcycles[\"Leader ID\"] = -1\n",
        "\n",
        "# Combine datasets\n",
        "combined = pd.concat([data, motorcycles], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'numpy.float64' object cannot be interpreted as an integer",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[23], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLeader ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_leader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;66;03m# End of a potential segment\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mvalidate_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfollower_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_leader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFrame ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_lane\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     53\u001b[0m             valid_pairs\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     54\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfollower_id\u001b[39m\u001b[38;5;124m'\u001b[39m: follower_id,\n\u001b[0;32m     55\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleader_id\u001b[39m\u001b[38;5;124m'\u001b[39m: current_leader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration_sec\u001b[39m\u001b[38;5;124m'\u001b[39m: (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrame ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m start_frame) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m     60\u001b[0m             })\n\u001b[0;32m     61\u001b[0m     current_leader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[23], line 27\u001b[0m, in \u001b[0;36mvalidate_segment\u001b[1;34m(follower_data, leader_id, start_frame, end_frame, lane_id, combined)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check 1: Leader has data for all frames in the segment\u001b[39;00m\n\u001b[0;32m     26\u001b[0m leader_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(leader_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrame ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m---> 27\u001b[0m required_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m leader_frames \u001b[38;5;241m!=\u001b[39m required_frames:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ensure data is sorted by Vehicle ID and Frame ID\n",
        "combined = combined.sort_values(by=['Vehicle ID', 'Frame ID'])\n",
        "\n",
        "# Create a helper function to validate segments\n",
        "def validate_segment(follower_data, leader_id, start_frame, end_frame, lane_id, combined):\n",
        "    \"\"\"\n",
        "    Check if a segment meets all criteria:\n",
        "    - Duration ≥20 seconds (≥200 frames)\n",
        "    - Leader exists for all frames in the segment\n",
        "    - Leader and follower stay in the same lane\n",
        "    \"\"\"\n",
        "    # Calculate duration (0.1 seconds per frame)\n",
        "    num_frames = end_frame - start_frame + 1\n",
        "    if num_frames < 200:\n",
        "        return False\n",
        "    \n",
        "    # Get leader's data for these frames\n",
        "    leader_data = combined[\n",
        "        (combined['Vehicle ID'] == leader_id) &\n",
        "        (combined['Frame ID'].between(start_frame, end_frame))\n",
        "    ]\n",
        "    \n",
        "    # Check 1: Leader has data for all frames in the segment\n",
        "    leader_frames = set(leader_data['Frame ID'].unique())\n",
        "    required_frames = set(range(start_frame, end_frame + 1))\n",
        "    \n",
        "    if leader_frames != required_frames:\n",
        "        return False\n",
        "    \n",
        "    # Check 2: Leader and follower stayed in the same lane\n",
        "    if (leader_data['Lane ID'] != lane_id).any():\n",
        "        return False\n",
        "    \n",
        "    return True\n",
        "\n",
        "# Main analysis\n",
        "valid_pairs = []\n",
        "\n",
        "# Group by follower vehicles\n",
        "for follower_id, follower_data in combined.groupby('Vehicle ID'):\n",
        "    current_leader = None\n",
        "    start_frame = None\n",
        "    current_lane = None\n",
        "    \n",
        "    for _, row in follower_data.iterrows():\n",
        "        # Skip rows with no leader\n",
        "        if row['Leader ID'] == -1:\n",
        "            if current_leader is not None:\n",
        "                # End of a potential segment\n",
        "                if validate_segment(follower_data, current_leader, start_frame, row['Frame ID'] - 1, current_lane, combined):\n",
        "                    valid_pairs.append({\n",
        "                        'follower_id': follower_id,\n",
        "                        'leader_id': current_leader,\n",
        "                        'start_frame': start_frame,\n",
        "                        'end_frame': row['Frame ID'] - 1,\n",
        "                        'lane_id': current_lane,\n",
        "                        'duration_sec': (row['Frame ID'] - start_frame) * 0.1\n",
        "                    })\n",
        "            current_leader = None\n",
        "            start_frame = None\n",
        "            current_lane = None\n",
        "            continue\n",
        "        \n",
        "        # Initialize or continue tracking\n",
        "        if row['Leader ID'] != current_leader or row['Lane ID'] != current_lane:\n",
        "            if current_leader is not None:\n",
        "                # Check previous segment\n",
        "                if validate_segment(follower_data, current_leader, start_frame, row['Frame ID'] - 1, current_lane, combined):\n",
        "                    valid_pairs.append({\n",
        "                        'follower_id': follower_id,\n",
        "                        'leader_id': current_leader,\n",
        "                        'start_frame': start_frame,\n",
        "                        'end_frame': row['Frame ID'] - 1,\n",
        "                        'lane_id': current_lane,\n",
        "                        'duration_sec': (row['Frame ID'] - start_frame) * 0.1\n",
        "                    })\n",
        "            \n",
        "            # Start new segment\n",
        "            current_leader = row['Leader ID']\n",
        "            start_frame = row['Frame ID']\n",
        "            current_lane = row['Lane ID']\n",
        "        else:\n",
        "            # Continue existing segment\n",
        "            pass\n",
        "\n",
        "# Convert results to DataFrame\n",
        "valid_pairs_df = pd.DataFrame(valid_pairs)\n",
        "\n",
        "# Filter duplicates (same pair in overlapping time windows)\n",
        "valid_pairs_df = valid_pairs_df.drop_duplicates(\n",
        "    subset=['follower_id', 'leader_id', 'lane_id'], \n",
        "    keep='first'\n",
        ")\n",
        "\n",
        "# Save results\n",
        "valid_pairs_df.to_csv('valid_car_following_pairs.csv', index=False)\n",
        "print(f\"Found {len(valid_pairs_df)} valid car-following pairs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Starting analysis...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: colorama in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (from tqdm) (0.4.6)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm\n",
            "Successfully installed tqdm-4.67.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]C:\\Users\\Raswanth\\AppData\\Local\\Temp\\ipykernel_48888\\1780113045.py:108: RuntimeWarning: divide by zero encountered in divide\n",
            "  time_headways = distances / follower_data['Speed'].values\n",
            "d:\\Anaconda\\envs\\tdsp\\Lib\\site-packages\\numpy\\_core\\_methods.py:191: RuntimeWarning: invalid value encountered in subtract\n",
            "  x = asanyarray(arr - arrmean)\n",
            "2it [03:08, 94.38s/it]\n",
            "INFO:__main__:Analysis complete. Found 999 car-following pairs.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analysis Summary:\n",
            "Total pairs found: 999\n",
            "\n",
            "Duration Statistics (seconds):\n",
            "Mean: 19.9\n",
            "Median: 19.9\n",
            "Min: 19.9\n",
            "Max: 19.9\n",
            "\n",
            "Following Distance Statistics (meters):\n",
            "Mean: 44.5\n",
            "Median: 42.8\n",
            "Min: 8.2\n",
            "Max: 95.1\n",
            "\n",
            "Time Headway Statistics (seconds):\n",
            "Mean: inf\n",
            "Median: 6.8\n",
            "Min: 1.2\n",
            "Max: inf\n"
          ]
        }
      ],
      "source": [
        "%pip install tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict, Generator, Optional\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm  # For progress bars\n",
        "import gc  # For garbage collection\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class TimeWindow:\n",
        "    \"\"\"Represents a time window for analysis to manage memory usage\"\"\"\n",
        "    start_frame: int\n",
        "    end_frame: int\n",
        "    \n",
        "    @property\n",
        "    def duration(self) -> float:\n",
        "        return (self.end_frame - self.start_frame) * 0.1  # Convert to seconds\n",
        "\n",
        "class StreamingDataLoader:\n",
        "    \"\"\"\n",
        "    Handles efficient loading and streaming of large trajectory files\n",
        "    \"\"\"\n",
        "    def __init__(self, filename: str, chunk_size: int = 100000):\n",
        "        self.filename = filename\n",
        "        self.chunk_size = chunk_size\n",
        "        \n",
        "    def get_chunks(self) -> Generator[pd.DataFrame, None, None]:\n",
        "        \"\"\"Yields chunks of data to process\"\"\"\n",
        "        # Define column names based on the data dictionary\n",
        "        columns = ['Vehicle_ID', 'Frame_ID', 'Lane_ID', 'LocalY', \n",
        "                  'Speed', 'Acceleration', 'Vehicle_Length', \n",
        "                  'Vehicle_Class', 'Follower_ID', 'Leader_ID']\n",
        "        \n",
        "        for chunk in pd.read_csv(self.filename, \n",
        "                               delimiter='\\s+',\n",
        "                               header=None,\n",
        "                               names=columns,\n",
        "                               chunksize=self.chunk_size):\n",
        "            # Basic data validation\n",
        "            chunk = chunk[chunk['Vehicle_ID'].notna()]\n",
        "            chunk = chunk[chunk['Lane_ID'].between(1, 7)]  # Valid lanes\n",
        "            yield chunk\n",
        "            \n",
        "    def get_time_windows(self, window_size: int = 1000) -> Generator[TimeWindow, None, None]:\n",
        "        \"\"\"Determine time windows for processing\"\"\"\n",
        "        min_frame = float('inf')\n",
        "        max_frame = -float('inf')\n",
        "        \n",
        "        # Find overall time range from first chunk\n",
        "        first_chunk = next(self.get_chunks())\n",
        "        min_frame = min(min_frame, first_chunk['Frame_ID'].min())\n",
        "        max_frame = max(max_frame, first_chunk['Frame_ID'].max())\n",
        "        \n",
        "        # Generate windows\n",
        "        current_frame = min_frame\n",
        "        while current_frame < max_frame:\n",
        "            yield TimeWindow(\n",
        "                start_frame=int(current_frame),\n",
        "                end_frame=int(min(current_frame + window_size, max_frame))\n",
        "            )\n",
        "            current_frame += window_size\n",
        "\n",
        "class CarFollowingPair:\n",
        "    \"\"\"Represents a validated car-following pair\"\"\"\n",
        "    def __init__(self, leader_id: int, follower_id: int, \n",
        "                 start_frame: int, end_frame: int, lane_id: int):\n",
        "        self.leader_id = leader_id\n",
        "        self.follower_id = follower_id\n",
        "        self.start_frame = start_frame\n",
        "        self.end_frame = end_frame\n",
        "        self.lane_id = lane_id\n",
        "        self.metrics = {}  # Store computed metrics\n",
        "        \n",
        "    @property\n",
        "    def duration(self) -> float:\n",
        "        return (self.end_frame - self.start_frame) * 0.1\n",
        "    \n",
        "    def compute_metrics(self, leader_data: pd.DataFrame, follower_data: pd.DataFrame) -> None:\n",
        "        \"\"\"Computes and stores various car-following metrics\"\"\"\n",
        "        # Ensure data is sorted by frame\n",
        "        leader_data = leader_data.sort_values('Frame_ID')\n",
        "        follower_data = follower_data.sort_values('Frame_ID')\n",
        "        \n",
        "        # Compute following distance statistics\n",
        "        distances = leader_data['LocalY'].values - follower_data['LocalY'].values\n",
        "        self.metrics.update({\n",
        "            'mean_distance': np.mean(distances),\n",
        "            'std_distance': np.std(distances),\n",
        "            'min_distance': np.min(distances),\n",
        "            'max_distance': np.max(distances)\n",
        "        })\n",
        "        \n",
        "        # Compute relative speed statistics\n",
        "        rel_speeds = leader_data['Speed'].values - follower_data['Speed'].values\n",
        "        self.metrics.update({\n",
        "            'mean_rel_speed': np.mean(rel_speeds),\n",
        "            'std_rel_speed': np.std(rel_speeds)\n",
        "        })\n",
        "        \n",
        "        # Compute time headway statistics\n",
        "        time_headways = distances / follower_data['Speed'].values\n",
        "        valid_headways = time_headways[~np.isnan(time_headways)]\n",
        "        self.metrics.update({\n",
        "            'mean_time_headway': np.mean(valid_headways),\n",
        "            'std_time_headway': np.std(valid_headways)\n",
        "        })\n",
        "\n",
        "class LargeScaleCarFollowingAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyzes car-following behavior in large datasets using windowed processing\n",
        "    \"\"\"\n",
        "    def __init__(self, min_duration: float = 20.0, \n",
        "                 min_distance: float = 2.0,\n",
        "                 max_distance: float = 100.0):\n",
        "        self.min_duration = min_duration\n",
        "        self.min_frames = int(min_duration * 10)\n",
        "        self.min_distance = min_distance\n",
        "        self.max_distance = max_distance\n",
        "        self.pairs: List[CarFollowingPair] = []\n",
        "        \n",
        "    def process_window(self, data: pd.DataFrame, window: TimeWindow) -> List[CarFollowingPair]:\n",
        "        \"\"\"\n",
        "        Processes a single time window to identify car-following pairs\n",
        "        \"\"\"\n",
        "        window_pairs = []\n",
        "        \n",
        "        # Group by lane\n",
        "        for lane_id, lane_data in data.groupby('Lane_ID'):\n",
        "            # Get unique vehicles in this lane during this window\n",
        "            vehicles = lane_data['Vehicle_ID'].unique()\n",
        "            \n",
        "            # Check each potential pair\n",
        "            for i, v1 in enumerate(vehicles[:-1]):\n",
        "                for v2 in vehicles[i+1:]:\n",
        "                    pair = self._analyze_vehicle_pair(\n",
        "                        lane_data[lane_data['Vehicle_ID'] == v1],\n",
        "                        lane_data[lane_data['Vehicle_ID'] == v2],\n",
        "                        lane_id\n",
        "                    )\n",
        "                    if pair is not None:\n",
        "                        window_pairs.append(pair)\n",
        "        \n",
        "        return window_pairs\n",
        "\n",
        "    def _analyze_vehicle_pair(self, v1_data: pd.DataFrame, \n",
        "                            v2_data: pd.DataFrame, \n",
        "                            lane_id: int) -> Optional[CarFollowingPair]:\n",
        "        \"\"\"\n",
        "        Analyzes a potential car-following pair\n",
        "        \"\"\"\n",
        "        # Find overlapping frames\n",
        "        common_frames = sorted(set(v1_data['Frame_ID']).intersection(set(v2_data['Frame_ID'])))\n",
        "        \n",
        "        if len(common_frames) < self.min_frames:\n",
        "            return None\n",
        "            \n",
        "        # Get positions at common frames\n",
        "        v1_positions = v1_data.set_index('Frame_ID')['LocalY']\n",
        "        v2_positions = v2_data.set_index('Frame_ID')['LocalY']\n",
        "        \n",
        "        # Determine consistent leader/follower relationship\n",
        "        leader_id = None\n",
        "        start_frame = None\n",
        "        consecutive_frames = 0\n",
        "        \n",
        "        for frame in common_frames:\n",
        "            pos1 = v1_positions[frame]\n",
        "            pos2 = v2_positions[frame]\n",
        "            \n",
        "            current_leader = v1_data['Vehicle_ID'].iloc[0] if pos1 > pos2 else v2_data['Vehicle_ID'].iloc[0]\n",
        "            \n",
        "            if leader_id is None:\n",
        "                leader_id = current_leader\n",
        "                start_frame = frame\n",
        "                consecutive_frames = 1\n",
        "            elif leader_id == current_leader:\n",
        "                consecutive_frames += 1\n",
        "            else:\n",
        "                leader_id = current_leader\n",
        "                start_frame = frame\n",
        "                consecutive_frames = 1\n",
        "                \n",
        "            # Check if we have a valid pair\n",
        "            if consecutive_frames >= self.min_frames:\n",
        "                follower_id = v2_data['Vehicle_ID'].iloc[0] if leader_id == v1_data['Vehicle_ID'].iloc[0] else v1_data['Vehicle_ID'].iloc[0]\n",
        "                \n",
        "                pair = CarFollowingPair(\n",
        "                    leader_id=leader_id,\n",
        "                    follower_id=follower_id,\n",
        "                    start_frame=start_frame,\n",
        "                    end_frame=frame,\n",
        "                    lane_id=lane_id\n",
        "                )\n",
        "                \n",
        "                # Compute metrics for validation\n",
        "                leader_data = v1_data if leader_id == v1_data['Vehicle_ID'].iloc[0] else v2_data\n",
        "                follower_data = v2_data if follower_id == v2_data['Vehicle_ID'].iloc[0] else v1_data\n",
        "                \n",
        "                pair.compute_metrics(\n",
        "                    leader_data[(leader_data['Frame_ID'] >= start_frame) & \n",
        "                              (leader_data['Frame_ID'] <= frame)],\n",
        "                    follower_data[(follower_data['Frame_ID'] >= start_frame) & \n",
        "                                (follower_data['Frame_ID'] <= frame)]\n",
        "                )\n",
        "                \n",
        "                # Validate distances\n",
        "                if (pair.metrics['min_distance'] >= self.min_distance and \n",
        "                    pair.metrics['max_distance'] <= self.max_distance):\n",
        "                    return pair\n",
        "                \n",
        "        return None\n",
        "\n",
        "    def analyze_file(self, filename: str) -> List[CarFollowingPair]:\n",
        "        \"\"\"\n",
        "        Main method to analyze a large trajectory file\n",
        "        \"\"\"\n",
        "        loader = StreamingDataLoader(filename)\n",
        "        \n",
        "        logger.info(\"Starting analysis...\")\n",
        "        for window in tqdm(loader.get_time_windows()):\n",
        "            # Load data for current window\n",
        "            window_data = pd.concat([\n",
        "                chunk[(chunk['Frame_ID'] >= window.start_frame) & \n",
        "                     (chunk['Frame_ID'] <= window.end_frame)]\n",
        "                for chunk in loader.get_chunks()\n",
        "            ])\n",
        "            \n",
        "            # Process window\n",
        "            window_pairs = self.process_window(window_data, window)\n",
        "            self.pairs.extend(window_pairs)\n",
        "            \n",
        "            # Clean up\n",
        "            del window_data\n",
        "            gc.collect()\n",
        "            \n",
        "        logger.info(f\"Analysis complete. Found {len(self.pairs)} car-following pairs.\")\n",
        "        return self.pairs\n",
        "\n",
        "def main():\n",
        "    # Initialize analyzer\n",
        "    analyzer = LargeScaleCarFollowingAnalyzer(\n",
        "        min_duration=20.0,\n",
        "        min_distance=2.0,\n",
        "        max_distance=100.0\n",
        "    )\n",
        "    \n",
        "    # Process the large data file\n",
        "    pairs = analyzer.analyze_file(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\DATA (NO MOTORCYCLES).txt\")\n",
        "    \n",
        "    # Print summary statistics\n",
        "    print(f\"\\nAnalysis Summary:\")\n",
        "    print(f\"Total pairs found: {len(pairs)}\")\n",
        "    \n",
        "    # Compute aggregate statistics\n",
        "    durations = [pair.duration for pair in pairs]\n",
        "    mean_distances = [pair.metrics['mean_distance'] for pair in pairs]\n",
        "    mean_headways = [pair.metrics['mean_time_headway'] for pair in pairs]\n",
        "    \n",
        "    print(f\"\\nDuration Statistics (seconds):\")\n",
        "    print(f\"Mean: {np.mean(durations):.1f}\")\n",
        "    print(f\"Median: {np.median(durations):.1f}\")\n",
        "    print(f\"Min: {np.min(durations):.1f}\")\n",
        "    print(f\"Max: {np.max(durations):.1f}\")\n",
        "    \n",
        "    print(f\"\\nFollowing Distance Statistics (meters):\")\n",
        "    print(f\"Mean: {np.mean(mean_distances):.1f}\")\n",
        "    print(f\"Median: {np.median(mean_distances):.1f}\")\n",
        "    print(f\"Min: {np.min(mean_distances):.1f}\")\n",
        "    print(f\"Max: {np.max(mean_distances):.1f}\")\n",
        "    \n",
        "    print(f\"\\nTime Headway Statistics (seconds):\")\n",
        "    print(f\"Mean: {np.mean(mean_headways):.1f}\")\n",
        "    print(f\"Median: {np.median(mean_headways):.1f}\")\n",
        "    print(f\"Min: {np.min(mean_headways):.1f}\")\n",
        "    print(f\"Max: {np.max(mean_headways):.1f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2029 valid car-following pairs\n",
            "\n",
            "Pair 1:\n",
            "Leader ID: 47.0\n",
            "Follower ID: 64.0\n",
            "Duration: 21.8 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 52.44\n",
            "  std: 18.54\n",
            "  min: 35.11\n",
            "  max: 99.71\n",
            "\n",
            "speed_difference:\n",
            "  mean: 2.83\n",
            "  std: 2.71\n",
            "  min: -1.43\n",
            "  max: 8.23\n",
            "\n",
            "time_headway:\n",
            "  mean: 4.71\n",
            "  std: 1.17\n",
            "  min: 3.39\n",
            "  max: 8.14\n",
            "\n",
            "Pair 2:\n",
            "Leader ID: 2142.0\n",
            "Follower ID: 2153.0\n",
            "Duration: 20.5 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 66.29\n",
            "  std: 15.14\n",
            "  min: 45.03\n",
            "  max: 99.59\n",
            "\n",
            "speed_difference:\n",
            "  mean: 2.67\n",
            "  std: 1.95\n",
            "  min: -0.61\n",
            "  max: 6.10\n",
            "\n",
            "time_headway:\n",
            "  mean: 4.73\n",
            "  std: 1.42\n",
            "  min: 2.75\n",
            "  max: 8.12\n",
            "\n",
            "Pair 3:\n",
            "Leader ID: 2.0\n",
            "Follower ID: 17.0\n",
            "Duration: 26.0 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 36.46\n",
            "  std: 10.12\n",
            "  min: 19.77\n",
            "  max: 57.29\n",
            "\n",
            "speed_difference:\n",
            "  mean: 1.36\n",
            "  std: 1.29\n",
            "  min: -1.81\n",
            "  max: 4.81\n",
            "\n",
            "time_headway:\n",
            "  mean: 2.82\n",
            "  std: 0.35\n",
            "  min: 2.17\n",
            "  max: 4.07\n",
            "\n",
            "Pair 4:\n",
            "Leader ID: 17.0\n",
            "Follower ID: 25.0\n",
            "Duration: 25.7 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 36.95\n",
            "  std: 10.31\n",
            "  min: 21.97\n",
            "  max: 50.71\n",
            "\n",
            "speed_difference:\n",
            "  mean: 0.87\n",
            "  std: 1.44\n",
            "  min: -4.18\n",
            "  max: 3.02\n",
            "\n",
            "time_headway:\n",
            "  mean: 2.71\n",
            "  std: 0.21\n",
            "  min: 2.12\n",
            "  max: 3.25\n",
            "\n",
            "Pair 5:\n",
            "Leader ID: 25.0\n",
            "Follower ID: 39.0\n",
            "Duration: 25.9 seconds\n",
            "Lane: 1\n",
            "\n",
            "Metrics:\n",
            "\n",
            "spacing:\n",
            "  mean: 31.29\n",
            "  std: 7.29\n",
            "  min: 21.87\n",
            "  max: 41.43\n",
            "\n",
            "speed_difference:\n",
            "  mean: 0.63\n",
            "  std: 1.08\n",
            "  min: -1.99\n",
            "  max: 2.43\n",
            "\n",
            "time_headway:\n",
            "  mean: 2.28\n",
            "  std: 0.19\n",
            "  min: 1.92\n",
            "  max: 3.14\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Dict, Tuple\n",
        "\n",
        "@dataclass\n",
        "class CarFollowingPair:\n",
        "    \"\"\"\n",
        "    Represents a validated car-following pair with all relevant information\n",
        "    \"\"\"\n",
        "    leader_id: int\n",
        "    follower_id: int\n",
        "    start_frame: int\n",
        "    end_frame: int\n",
        "    lane_id: int\n",
        "    metrics: Dict = None\n",
        "\n",
        "    @property\n",
        "    def duration(self) -> float:\n",
        "        \"\"\"Duration of car-following episode in seconds\"\"\"\n",
        "        return (self.end_frame - self.start_frame + 1) * 0.1  # Convert frames to seconds\n",
        "\n",
        "class CarFollowingIdentifier:\n",
        "    \"\"\"\n",
        "    Identifies and validates car-following pairs in trajectory data\n",
        "    \"\"\"\n",
        "    def __init__(self, min_duration: float = 20.0,\n",
        "                 min_spacing: float = 2.0,\n",
        "                 max_spacing: float = 100.0):\n",
        "        \"\"\"\n",
        "        Initialize with validation criteria\n",
        "        \n",
        "        Parameters:\n",
        "        min_duration: Minimum duration in seconds for valid car-following\n",
        "        min_spacing: Minimum allowed spacing between vehicles (meters)\n",
        "        max_spacing: Maximum allowed spacing between vehicles (meters)\n",
        "        \"\"\"\n",
        "        self.min_duration = min_duration\n",
        "        self.min_frames = int(min_duration * 10)  # Convert to frames (0.1s intervals)\n",
        "        self.min_spacing = min_spacing\n",
        "        self.max_spacing = max_spacing\n",
        "        \n",
        "    def identify_pairs(self, df: pd.DataFrame) -> List[CarFollowingPair]:\n",
        "        \"\"\"\n",
        "        Main method to identify valid car-following pairs\n",
        "        \n",
        "        Parameters:\n",
        "        df: DataFrame with columns for Vehicle_ID, Frame_ID, Lane_ID, LocalY\n",
        "        \n",
        "        Returns:\n",
        "        List of validated CarFollowingPair objects\n",
        "        \"\"\"\n",
        "        valid_pairs = []\n",
        "        \n",
        "        # Step 1: Group data by lane\n",
        "        for lane_id, lane_data in df.groupby('Lane_ID'):\n",
        "            # Skip special lanes (like merge lanes or shoulders)\n",
        "            if lane_id > 6:  # Assuming regular lanes are 1-6\n",
        "                continue\n",
        "                \n",
        "            # Step 2: Process each time window in the lane\n",
        "            frames = sorted(lane_data['Frame_ID'].unique())\n",
        "            \n",
        "            # Step 3: For each frame, identify potential pairs\n",
        "            current_pairs = {}  # Track ongoing pairs\n",
        "            \n",
        "            for frame in frames:\n",
        "                frame_data = lane_data[lane_data['Frame_ID'] == frame]\n",
        "                \n",
        "                # Sort vehicles by position to identify leader-follower relationships\n",
        "                frame_vehicles = frame_data.sort_values('LocalY', ascending=False)\n",
        "                \n",
        "                # Step 4: Check each consecutive pair of vehicles\n",
        "                for i in range(len(frame_vehicles) - 1):\n",
        "                    leader = frame_vehicles.iloc[i]\n",
        "                    follower = frame_vehicles.iloc[i + 1]\n",
        "                    \n",
        "                    pair_id = (leader['Vehicle_ID'], follower['Vehicle_ID'])\n",
        "                    \n",
        "                    # Calculate spacing\n",
        "                    spacing = leader['LocalY'] - follower['LocalY']\n",
        "                    \n",
        "                    # Validate spacing\n",
        "                    if self.min_spacing <= spacing <= self.max_spacing:\n",
        "                        if pair_id not in current_pairs:\n",
        "                            # Start new pair tracking\n",
        "                            current_pairs[pair_id] = {\n",
        "                                'start_frame': frame,\n",
        "                                'current_frame': frame,\n",
        "                                'lane_id': lane_id\n",
        "                            }\n",
        "                        else:\n",
        "                            # Update existing pair\n",
        "                            current_pairs[pair_id]['current_frame'] = frame\n",
        "                    else:\n",
        "                        # Invalid spacing - end pair if exists\n",
        "                        self._check_and_add_pair(current_pairs, pair_id, valid_pairs)\n",
        "            \n",
        "            # Process any remaining pairs\n",
        "            for pair_id in list(current_pairs.keys()):\n",
        "                self._check_and_add_pair(current_pairs, pair_id, valid_pairs)\n",
        "        \n",
        "        return valid_pairs\n",
        "    \n",
        "    def _check_and_add_pair(self, current_pairs: Dict, \n",
        "                           pair_id: Tuple[int, int],\n",
        "                           valid_pairs: List[CarFollowingPair]) -> None:\n",
        "        \"\"\"\n",
        "        Validates and adds a car-following pair if it meets duration criteria\n",
        "        \"\"\"\n",
        "        if pair_id in current_pairs:\n",
        "            pair_data = current_pairs[pair_id]\n",
        "            duration_frames = pair_data['current_frame'] - pair_data['start_frame'] + 1\n",
        "            \n",
        "            if duration_frames >= self.min_frames:\n",
        "                # Create validated pair\n",
        "                valid_pairs.append(CarFollowingPair(\n",
        "                    leader_id=pair_id[0],\n",
        "                    follower_id=pair_id[1],\n",
        "                    start_frame=pair_data['start_frame'],\n",
        "                    end_frame=pair_data['current_frame'],\n",
        "                    lane_id=pair_data['lane_id']\n",
        "                ))\n",
        "            \n",
        "            # Remove pair from tracking\n",
        "            del current_pairs[pair_id]\n",
        "    \n",
        "    def compute_pair_metrics(self, pair: CarFollowingPair, \n",
        "                           df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"\n",
        "        Computes detailed metrics for a validated car-following pair\n",
        "        \n",
        "        Parameters:\n",
        "        pair: CarFollowingPair object\n",
        "        df: Original trajectory DataFrame\n",
        "        \n",
        "        Returns:\n",
        "        Dictionary of computed metrics\n",
        "        \"\"\"\n",
        "        # Get leader and follower trajectories\n",
        "        leader_data = df[(df['Vehicle_ID'] == pair.leader_id) & \n",
        "                        (df['Frame_ID'] >= pair.start_frame) & \n",
        "                        (df['Frame_ID'] <= pair.end_frame)]\n",
        "        \n",
        "        follower_data = df[(df['Vehicle_ID'] == pair.follower_id) & \n",
        "                          (df['Frame_ID'] >= pair.start_frame) & \n",
        "                          (df['Frame_ID'] <= pair.end_frame)]\n",
        "        \n",
        "        # Compute spacing statistics\n",
        "        spacing = leader_data['LocalY'].values - follower_data['LocalY'].values\n",
        "        \n",
        "        # Compute speed difference statistics\n",
        "        speed_diff = leader_data['Speed'].values - follower_data['Speed'].values\n",
        "        \n",
        "        # Compute time headway\n",
        "        time_headway = spacing / follower_data['Speed'].values\n",
        "        valid_headway = time_headway[~np.isinf(time_headway)]\n",
        "        \n",
        "        return {\n",
        "            'spacing': {\n",
        "                'mean': np.mean(spacing),\n",
        "                'std': np.std(spacing),\n",
        "                'min': np.min(spacing),\n",
        "                'max': np.max(spacing)\n",
        "            },\n",
        "            'speed_difference': {\n",
        "                'mean': np.mean(speed_diff),\n",
        "                'std': np.std(speed_diff),\n",
        "                'min': np.min(speed_diff),\n",
        "                'max': np.max(speed_diff)\n",
        "            },\n",
        "            'time_headway': {\n",
        "                'mean': np.mean(valid_headway),\n",
        "                'std': np.std(valid_headway),\n",
        "                'min': np.min(valid_headway),\n",
        "                'max': np.max(valid_headway)\n",
        "            }\n",
        "        }\n",
        "\n",
        "def main():\n",
        "    # Example usage\n",
        "    # Read the data file\n",
        "    df = pd.read_csv(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\DATA (NO MOTORCYCLES).txt\", delimiter='\\s+', header=None,\n",
        "                     names=['Vehicle_ID', 'Frame_ID', 'Lane_ID', 'LocalY',\n",
        "                           'Speed', 'Acceleration', 'Vehicle_Length',\n",
        "                           'Vehicle_Class', 'Follower_ID', 'Leader_ID'])\n",
        "    \n",
        "    # Initialize identifier\n",
        "    identifier = CarFollowingIdentifier(\n",
        "        min_duration=20.0,  # 20 seconds minimum\n",
        "        min_spacing=2.0,    # 2 meters minimum spacing\n",
        "        max_spacing=100.0   # 100 meters maximum spacing\n",
        "    )\n",
        "    \n",
        "    # Find car-following pairs\n",
        "    pairs = identifier.identify_pairs(df)\n",
        "    \n",
        "    # Print summary\n",
        "    print(f\"Found {len(pairs)} valid car-following pairs\")\n",
        "    \n",
        "    # Analyze first few pairs\n",
        "    for i, pair in enumerate(pairs[:5]):\n",
        "        print(f\"\\nPair {i+1}:\")\n",
        "        print(f\"Leader ID: {pair.leader_id}\")\n",
        "        print(f\"Follower ID: {pair.follower_id}\")\n",
        "        print(f\"Duration: {pair.duration:.1f} seconds\")\n",
        "        print(f\"Lane: {pair.lane_id}\")\n",
        "        \n",
        "        # Compute and print metrics\n",
        "        metrics = identifier.compute_pair_metrics(pair, df)\n",
        "        print(\"\\nMetrics:\")\n",
        "        for metric, values in metrics.items():\n",
        "            print(f\"\\n{metric}:\")\n",
        "            for stat, value in values.items():\n",
        "                print(f\"  {stat}: {value:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "class CarFollowingVisualizer:\n",
        "    \"\"\"\n",
        "    Creates detailed visualizations for car-following pairs, showing speed profiles\n",
        "    and space gaps over time with comprehensive metrics.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_file):\n",
        "        \"\"\"\n",
        "        Initialize with the path to the trajectory data file.\n",
        "        \"\"\"\n",
        "        # Read the full trajectory data\n",
        "        self.df = pd.read_csv(data_file, \n",
        "                            delimiter='\\s+',\n",
        "                            header=None,\n",
        "                            names=['Vehicle_ID', 'Frame_ID', 'Lane_ID', 'LocalY',\n",
        "                                  'Speed', 'Acceleration', 'Vehicle_Length',\n",
        "                                  'Vehicle_Class', 'Follower_ID', 'Leader_ID'])\n",
        "\n",
        "    def extract_pair_data(self, leader_id, follower_id, start_frame, end_frame):\n",
        "        \"\"\"\n",
        "        Extracts trajectory data for a specific leader-follower pair.\n",
        "        \"\"\"\n",
        "        # Get leader trajectory\n",
        "        leader_data = self.df[\n",
        "            (self.df['Vehicle_ID'] == leader_id) &\n",
        "            (self.df['Frame_ID'] >= start_frame) &\n",
        "            (self.df['Frame_ID'] <= end_frame)\n",
        "        ].sort_values('Frame_ID')\n",
        "        \n",
        "        # Get follower trajectory\n",
        "        follower_data = self.df[\n",
        "            (self.df['Vehicle_ID'] == follower_id) &\n",
        "            (self.df['Frame_ID'] >= start_frame) &\n",
        "            (self.df['Frame_ID'] <= end_frame)\n",
        "        ].sort_values('Frame_ID')\n",
        "        \n",
        "        # Create time array (convert frames to seconds)\n",
        "        time = (leader_data['Frame_ID'] - start_frame) * 0.1\n",
        "        \n",
        "        return {\n",
        "            'time': time,\n",
        "            'leader_speed': leader_data['Speed'].values,\n",
        "            'follower_speed': follower_data['Speed'].values,\n",
        "            'spacing': leader_data['LocalY'].values - follower_data['LocalY'].values\n",
        "        }\n",
        "\n",
        "    def plot_pair(self, pair_info, metrics):\n",
        "        \"\"\"\n",
        "        Creates a comprehensive visualization for a single car-following pair.\n",
        "        \"\"\"\n",
        "        # Extract pair data\n",
        "        data = self.extract_pair_data(\n",
        "            pair_info['leader_id'],\n",
        "            pair_info['follower_id'],\n",
        "            pair_info['start_frame'],\n",
        "            pair_info['end_frame']\n",
        "        )\n",
        "        \n",
        "        # Create figure with grid layout\n",
        "        fig = plt.figure(figsize=(12, 8))\n",
        "        gs = GridSpec(2, 2, figure=fig)\n",
        "        \n",
        "        # Speed profiles subplot (larger)\n",
        "        ax1 = fig.add_subplot(gs[0, :])\n",
        "        ax1.plot(data['time'], data['leader_speed'], 'b-', label='Leader Speed', linewidth=2)\n",
        "        ax1.plot(data['time'], data['follower_speed'], 'r--', label='Follower Speed', linewidth=2)\n",
        "        ax1.set_xlabel('Time (seconds)')\n",
        "        ax1.set_ylabel('Speed (m/s)')\n",
        "        ax1.set_title('Speed Profiles')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "        \n",
        "        # Space gap subplot\n",
        "        ax2 = fig.add_subplot(gs[1, 0])\n",
        "        ax2.plot(data['time'], data['spacing'], 'g-', linewidth=2)\n",
        "        ax2.set_xlabel('Time (seconds)')\n",
        "        ax2.set_ylabel('Space Gap (m)')\n",
        "        ax2.set_title('Following Distance')\n",
        "        ax2.grid(True)\n",
        "        \n",
        "        # Metrics text box\n",
        "        ax3 = fig.add_subplot(gs[1, 1])\n",
        "        ax3.axis('off')\n",
        "        metrics_text = (\n",
        "            f\"Pair Metrics:\\n\\n\"\n",
        "            f\"Duration: {pair_info['duration']:.1f} seconds\\n\\n\"\n",
        "            f\"Spacing (m):\\n\"\n",
        "            f\"  Mean: {metrics['spacing']['mean']:.2f}\\n\"\n",
        "            f\"  Std: {metrics['spacing']['std']:.2f}\\n\"\n",
        "            f\"  Min: {metrics['spacing']['min']:.2f}\\n\"\n",
        "            f\"  Max: {metrics['spacing']['max']:.2f}\\n\\n\"\n",
        "            f\"Speed Difference (m/s):\\n\"\n",
        "            f\"  Mean: {metrics['speed_difference']['mean']:.2f}\\n\"\n",
        "            f\"  Std: {metrics['speed_difference']['std']:.2f}\\n\\n\"\n",
        "            f\"Time Headway (s):\\n\"\n",
        "            f\"  Mean: {metrics['time_headway']['mean']:.2f}\\n\"\n",
        "            f\"  Std: {metrics['time_headway']['std']:.2f}\"\n",
        "        )\n",
        "        ax3.text(0.05, 0.95, metrics_text,\n",
        "                verticalalignment='top',\n",
        "                fontfamily='monospace',\n",
        "                bbox=dict(facecolor='white', alpha=0.8))\n",
        "        \n",
        "        # Add overall title\n",
        "        plt.suptitle(f'Car-Following Pair Analysis\\n'\n",
        "                    f'Leader ID: {pair_info[\"leader_id\"]}, '\n",
        "                    f'Follower ID: {pair_info[\"follower_id\"]}, '\n",
        "                    f'Lane: {pair_info[\"lane\"]}',\n",
        "                    y=0.98)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "def visualize_pairs(data_file=\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\DATA (NO MOTORCYCLES).txt\"):\n",
        "    \"\"\"\n",
        "    Creates visualizations for the specified car-following pairs.\n",
        "    \"\"\"\n",
        "    # Create visualizer\n",
        "    visualizer = CarFollowingVisualizer(data_file)\n",
        "    \n",
        "    # Define the pairs we want to visualize (from the output)\n",
        "    pairs = [\n",
        "        {\n",
        "            'leader_id': 47.0, 'follower_id': 64.0,\n",
        "            'start_frame': 0, 'end_frame': 218,  # 21.8 seconds\n",
        "            'duration': 21.8, 'lane': 1\n",
        "        },\n",
        "        {\n",
        "            'leader_id': 2142.0, 'follower_id': 2153.0,\n",
        "            'start_frame': 0, 'end_frame': 205,  # 20.5 seconds\n",
        "            'duration': 20.5, 'lane': 1\n",
        "        },\n",
        "        {\n",
        "            'leader_id': 2.0, 'follower_id': 17.0,\n",
        "            'start_frame': 0, 'end_frame': 260,  # 26.0 seconds\n",
        "            'duration': 26.0, 'lane': 1\n",
        "        },\n",
        "        {\n",
        "            'leader_id': 17.0, 'follower_id': 25.0,\n",
        "            'start_frame': 0, 'end_frame': 257,  # 25.7 seconds\n",
        "            'duration': 25.7, 'lane': 1\n",
        "        },\n",
        "        {\n",
        "            'leader_id': 25.0, 'follower_id': 39.0,\n",
        "            'start_frame': 0, 'end_frame': 259,  # 25.9 seconds\n",
        "            'duration': 25.9, 'lane': 1\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    # Create visualizations for each pair\n",
        "    for i, pair in enumerate(pairs, 1):\n",
        "        # Get metrics from the output\n",
        "        metrics = {\n",
        "            'spacing': {\n",
        "                'mean': [52.44, 66.29, 36.46, 36.95, 31.29][i-1],\n",
        "                'std': [18.54, 15.14, 10.12, 10.31, 7.29][i-1],\n",
        "                'min': [35.11, 45.03, 19.77, 21.97, 21.87][i-1],\n",
        "                'max': [99.71, 99.59, 57.29, 50.71, 41.43][i-1]\n",
        "            },\n",
        "            'speed_difference': {\n",
        "                'mean': [2.83, 2.67, 1.36, 0.87, 0.63][i-1],\n",
        "                'std': [2.71, 1.95, 1.29, 1.44, 1.08][i-1],\n",
        "                'min': [-1.43, -0.61, -1.81, -4.18, -1.99][i-1],\n",
        "                'max': [8.23, 6.10, 4.81, 3.02, 2.43][i-1]\n",
        "            },\n",
        "            'time_headway': {\n",
        "                'mean': [4.71, 4.73, 2.82, 2.71, 2.28][i-1],\n",
        "                'std': [1.17, 1.42, 0.35, 0.21, 0.19][i-1],\n",
        "                'min': [3.39, 2.75, 2.17, 2.12, 1.92][i-1],\n",
        "                'max': [8.14, 8.12, 4.07, 3.25, 3.14][i-1]\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        # Create visualization\n",
        "        fig = visualizer.plot_pair(pair, metrics)\n",
        "        \n",
        "        # Save the figure\n",
        "        plt.savefig(f'car_following_pair_{i}.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    visualize_pairs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Raswanth\\AppData\\Local\\Temp\\ipykernel_48888\\2365191884.py:110: RuntimeWarning: divide by zero encountered in divide\n",
            "  time_headway = spacing / follower_data['Speed'].values\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary Statistics:\n",
            "         spacing  time_headway  relative_speed\n",
            "mean   19.713641      3.221234       -0.008538\n",
            "std     4.778569      1.819268        1.255265\n",
            "min     3.516840      0.387688      -10.545680\n",
            "max   126.281730    546.928879       13.817540\n",
            "\n",
            "Generating visualizations for first 5 pairs...\n",
            "\n",
            "Pair 1 Metrics:\n",
            "\n",
            "Spacing:\n",
            "  mean: 13.24\n",
            "  std: 7.48\n",
            "  min: 6.52\n",
            "  max: 38.02\n",
            "\n",
            "Relative_Speed:\n",
            "  mean: -0.99\n",
            "  std: 2.43\n",
            "  min: -7.16\n",
            "  max: 2.13\n",
            "\n",
            "Time_Headway:\n",
            "  mean: 5.67\n",
            "  std: 4.40\n",
            "  min: 1.66\n",
            "  max: 28.36\n",
            "\n",
            "Pair 2 Metrics:\n",
            "\n",
            "Spacing:\n",
            "  mean: 14.51\n",
            "  std: 4.76\n",
            "  min: 7.36\n",
            "  max: 25.12\n",
            "\n",
            "Relative_Speed:\n",
            "  mean: 0.17\n",
            "  std: 1.15\n",
            "  min: -2.28\n",
            "  max: 2.67\n",
            "\n",
            "Time_Headway:\n",
            "  mean: 3.49\n",
            "  std: 5.21\n",
            "  min: 1.39\n",
            "  max: 67.51\n",
            "\n",
            "Pair 3 Metrics:\n",
            "\n",
            "Spacing:\n",
            "  mean: 18.18\n",
            "  std: 7.66\n",
            "  min: 8.13\n",
            "  max: 36.55\n",
            "\n",
            "Relative_Speed:\n",
            "  mean: 0.07\n",
            "  std: 1.46\n",
            "  min: -4.34\n",
            "  max: 3.84\n",
            "\n",
            "Time_Headway:\n",
            "  mean: 3.40\n",
            "  std: 1.01\n",
            "  min: 2.00\n",
            "  max: 7.10\n",
            "\n",
            "Pair 4 Metrics:\n",
            "\n",
            "Spacing:\n",
            "  mean: 13.97\n",
            "  std: 2.88\n",
            "  min: 8.60\n",
            "  max: 20.62\n",
            "\n",
            "Relative_Speed:\n",
            "  mean: 0.04\n",
            "  std: 1.09\n",
            "  min: -4.10\n",
            "  max: 2.03\n",
            "\n",
            "Time_Headway:\n",
            "  mean: 3.26\n",
            "  std: 1.88\n",
            "  min: 1.59\n",
            "  max: 11.55\n",
            "\n",
            "Pair 5 Metrics:\n",
            "\n",
            "Spacing:\n",
            "  mean: 36.46\n",
            "  std: 10.12\n",
            "  min: 19.77\n",
            "  max: 57.29\n",
            "\n",
            "Relative_Speed:\n",
            "  mean: 1.36\n",
            "  std: 1.29\n",
            "  min: -1.81\n",
            "  max: 4.81\n",
            "\n",
            "Time_Headway:\n",
            "  mean: 2.82\n",
            "  std: 0.35\n",
            "  min: 2.17\n",
            "  max: 4.07\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "class CarFollowingStatistics:\n",
        "    \"\"\"\n",
        "    Analyzes statistical properties of car-following pairs and generates\n",
        "    comprehensive visualizations and analyses.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_file: str):\n",
        "        \"\"\"\n",
        "        Initialize with path to trajectory data file\n",
        "        \"\"\"\n",
        "        self.data_file = data_file\n",
        "        self.pairs_data = []\n",
        "        self.summary_stats = {}\n",
        "        self.pair_metrics = {}\n",
        "        \n",
        "    def load_and_process_data(self):\n",
        "        \"\"\"\n",
        "        Loads trajectory data and processes it to identify car-following pairs\n",
        "        \"\"\"\n",
        "        # Read the data file\n",
        "        df = pd.read_csv(self.data_file, \n",
        "                        delimiter='\\s+',\n",
        "                        header=None,\n",
        "                        names=['Vehicle_ID', 'Frame_ID', 'Lane_ID', 'LocalY',\n",
        "                              'Speed', 'Acceleration', 'Vehicle_Length',\n",
        "                              'Vehicle_Class', 'Follower_ID', 'Leader_ID'])\n",
        "        \n",
        "        # Process data into car-following pairs\n",
        "        MIN_DURATION = 200  # 20 seconds at 0.1s intervals\n",
        "        \n",
        "        # Group by follower vehicle\n",
        "        for vehicle_id, vehicle_data in df.groupby('Vehicle_ID'):\n",
        "            # Find continuous following periods\n",
        "            following_periods = self._find_following_periods(vehicle_data, MIN_DURATION)\n",
        "            \n",
        "            for period in following_periods:\n",
        "                # Extract leader and follower trajectories\n",
        "                pair_data = self._extract_pair_trajectories(\n",
        "                    df, period['leader_id'], vehicle_id,\n",
        "                    period['start_frame'], period['end_frame']\n",
        "                )\n",
        "                \n",
        "                if pair_data is not None:\n",
        "                    self.pairs_data.append(pair_data)\n",
        "    \n",
        "    def _find_following_periods(self, vehicle_data: pd.DataFrame, \n",
        "                              min_duration: int) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Identifies continuous periods where the vehicle follows another vehicle\n",
        "        \"\"\"\n",
        "        periods = []\n",
        "        current_leader = None\n",
        "        start_frame = None\n",
        "        \n",
        "        for _, row in vehicle_data.iterrows():\n",
        "            if row['Leader_ID'] != -1:  # Valid leader exists\n",
        "                if current_leader is None:\n",
        "                    current_leader = row['Leader_ID']\n",
        "                    start_frame = row['Frame_ID']\n",
        "                elif row['Leader_ID'] != current_leader:\n",
        "                    # Leader changed, check if previous period is valid\n",
        "                    if row['Frame_ID'] - start_frame >= min_duration:\n",
        "                        periods.append({\n",
        "                            'leader_id': current_leader,\n",
        "                            'start_frame': start_frame,\n",
        "                            'end_frame': row['Frame_ID'] - 1\n",
        "                        })\n",
        "                    current_leader = row['Leader_ID']\n",
        "                    start_frame = row['Frame_ID']\n",
        "            else:\n",
        "                # No leader, end current period if exists\n",
        "                if current_leader is not None and \\\n",
        "                   row['Frame_ID'] - start_frame >= min_duration:\n",
        "                    periods.append({\n",
        "                        'leader_id': current_leader,\n",
        "                        'start_frame': start_frame,\n",
        "                        'end_frame': row['Frame_ID'] - 1\n",
        "                    })\n",
        "                current_leader = None\n",
        "                \n",
        "        return periods\n",
        "    \n",
        "    def _extract_pair_trajectories(self, df: pd.DataFrame,\n",
        "                                 leader_id: int, follower_id: int,\n",
        "                                 start_frame: int, end_frame: int) -> Dict:\n",
        "        \"\"\"\n",
        "        Extracts and processes trajectory data for a leader-follower pair\n",
        "        \"\"\"\n",
        "        # Get leader and follower data for the period\n",
        "        leader_data = df[(df['Vehicle_ID'] == leader_id) &\n",
        "                        (df['Frame_ID'] >= start_frame) &\n",
        "                        (df['Frame_ID'] <= end_frame)]\n",
        "        \n",
        "        follower_data = df[(df['Vehicle_ID'] == follower_id) &\n",
        "                          (df['Frame_ID'] >= start_frame) &\n",
        "                          (df['Frame_ID'] <= end_frame)]\n",
        "        \n",
        "        if len(leader_data) == 0 or len(follower_data) == 0:\n",
        "            return None\n",
        "            \n",
        "        # Calculate metrics\n",
        "        spacing = leader_data['LocalY'].values - follower_data['LocalY'].values\n",
        "        relative_speed = leader_data['Speed'].values - follower_data['Speed'].values\n",
        "        time_headway = spacing / follower_data['Speed'].values\n",
        "        \n",
        "        return {\n",
        "            'pair_id': f\"{leader_id}-{follower_id}\",\n",
        "            'leader_id': leader_id,\n",
        "            'follower_id': follower_id,\n",
        "            'start_frame': start_frame,\n",
        "            'end_frame': end_frame,\n",
        "            'duration': (end_frame - start_frame) * 0.1,\n",
        "            'metrics': {\n",
        "                'spacing': {\n",
        "                    'mean': np.mean(spacing),\n",
        "                    'std': np.std(spacing),\n",
        "                    'min': np.min(spacing),\n",
        "                    'max': np.max(spacing)\n",
        "                },\n",
        "                'relative_speed': {\n",
        "                    'mean': np.mean(relative_speed),\n",
        "                    'std': np.std(relative_speed),\n",
        "                    'min': np.min(relative_speed),\n",
        "                    'max': np.max(relative_speed)\n",
        "                },\n",
        "                'time_headway': {\n",
        "                    'mean': np.mean(time_headway[~np.isinf(time_headway)]),\n",
        "                    'std': np.std(time_headway[~np.isinf(time_headway)]),\n",
        "                    'min': np.min(time_headway[~np.isinf(time_headway)]),\n",
        "                    'max': np.max(time_headway[~np.isinf(time_headway)])\n",
        "                }\n",
        "            },\n",
        "            'trajectories': {\n",
        "                'time': np.arange(0, (end_frame - start_frame + 1) * 0.1, 0.1),\n",
        "                'leader_speed': leader_data['Speed'].values,\n",
        "                'follower_speed': follower_data['Speed'].values,\n",
        "                'spacing': spacing,\n",
        "                'relative_speed': relative_speed,\n",
        "                'time_headway': time_headway\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def generate_pair_visualizations(self, pair_data: Dict):\n",
        "        \"\"\"\n",
        "        Generates comprehensive visualizations for a single car-following pair\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(3, 1, figsize=(12, 15))\n",
        "        \n",
        "        # Speed profiles\n",
        "        axes[0].plot(pair_data['trajectories']['time'],\n",
        "                    pair_data['trajectories']['leader_speed'],\n",
        "                    label='Leader')\n",
        "        axes[0].plot(pair_data['trajectories']['time'],\n",
        "                    pair_data['trajectories']['follower_speed'],\n",
        "                    label='Follower')\n",
        "        axes[0].set_xlabel('Time (s)')\n",
        "        axes[0].set_ylabel('Speed (m/s)')\n",
        "        axes[0].set_title('Speed Profiles')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True)\n",
        "        \n",
        "        # Space gap\n",
        "        axes[1].plot(pair_data['trajectories']['time'],\n",
        "                    pair_data['trajectories']['spacing'])\n",
        "        axes[1].set_xlabel('Time (s)')\n",
        "        axes[1].set_ylabel('Space Gap (m)')\n",
        "        axes[1].set_title('Following Distance')\n",
        "        axes[1].grid(True)\n",
        "        \n",
        "        # Time headway\n",
        "        valid_headway = pair_data['trajectories']['time_headway']\n",
        "        valid_headway = valid_headway[~np.isinf(valid_headway)]\n",
        "        valid_time = pair_data['trajectories']['time'][:len(valid_headway)]\n",
        "        \n",
        "        axes[2].plot(valid_time, valid_headway)\n",
        "        axes[2].set_xlabel('Time (s)')\n",
        "        axes[2].set_ylabel('Time Headway (s)')\n",
        "        axes[2].set_title('Time Headway')\n",
        "        axes[2].grid(True)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "    \n",
        "    def generate_summary_statistics(self):\n",
        "        \"\"\"\n",
        "        Generates summary statistics across all car-following pairs\n",
        "        \"\"\"\n",
        "        self.summary_stats = {\n",
        "            'spacing': {\n",
        "                'mean': np.mean([p['metrics']['spacing']['mean'] for p in self.pairs_data]),\n",
        "                'std': np.mean([p['metrics']['spacing']['std'] for p in self.pairs_data]),\n",
        "                'min': np.min([p['metrics']['spacing']['min'] for p in self.pairs_data]),\n",
        "                'max': np.max([p['metrics']['spacing']['max'] for p in self.pairs_data])\n",
        "            },\n",
        "            'time_headway': {\n",
        "                'mean': np.mean([p['metrics']['time_headway']['mean'] for p in self.pairs_data]),\n",
        "                'std': np.mean([p['metrics']['time_headway']['std'] for p in self.pairs_data]),\n",
        "                'min': np.min([p['metrics']['time_headway']['min'] for p in self.pairs_data]),\n",
        "                'max': np.max([p['metrics']['time_headway']['max'] for p in self.pairs_data])\n",
        "            },\n",
        "            'relative_speed': {\n",
        "                'mean': np.mean([p['metrics']['relative_speed']['mean'] for p in self.pairs_data]),\n",
        "                'std': np.mean([p['metrics']['relative_speed']['std'] for p in self.pairs_data]),\n",
        "                'min': np.min([p['metrics']['relative_speed']['min'] for p in self.pairs_data]),\n",
        "                'max': np.max([p['metrics']['relative_speed']['max'] for p in self.pairs_data])\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        return pd.DataFrame(self.summary_stats)\n",
        "\n",
        "def main():\n",
        "    # Initialize analyzer\n",
        "    analyzer = CarFollowingStatistics(\"D:\\ASU Academics\\Traffic Flow Theroy\\MP-1\\Reconstructed NGSIM I80-1 data\\Data\\DATA (NO MOTORCYCLES).txt\")\n",
        "    \n",
        "    # Load and process data\n",
        "    analyzer.load_and_process_data()\n",
        "    \n",
        "    # Generate summary statistics\n",
        "    summary_stats = analyzer.generate_summary_statistics()\n",
        "    print(\"\\nSummary Statistics:\")\n",
        "    print(summary_stats)\n",
        "    \n",
        "    # Generate visualizations for first 5 pairs\n",
        "    print(\"\\nGenerating visualizations for first 5 pairs...\")\n",
        "    for i, pair_data in enumerate(analyzer.pairs_data[:5]):\n",
        "        fig = analyzer.generate_pair_visualizations(pair_data)\n",
        "        fig.suptitle(f'Car-Following Pair {pair_data[\"pair_id\"]}')\n",
        "        plt.savefig(f'pair_{i+1}_analysis.png')\n",
        "        plt.close()\n",
        "        \n",
        "        print(f\"\\nPair {i+1} Metrics:\")\n",
        "        for metric, values in pair_data['metrics'].items():\n",
        "            print(f\"\\n{metric.title()}:\")\n",
        "            for stat, value in values.items():\n",
        "                print(f\"  {stat}: {value:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-04 23:57:02,205 - __main__ - ERROR - Error loading data: Error tokenizing data. C error: Expected 62 fields in line 1602, saw 63\n",
            "\n",
            "2025-02-04 23:57:02,205 - __main__ - ERROR - Error loading data: Error tokenizing data. C error: Expected 62 fields in line 1602, saw 63\n",
            "\n",
            "ERROR:__main__:Error loading data: Error tokenizing data. C error: Expected 62 fields in line 1602, saw 63\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (2.2.1)\n",
            "Requirement already satisfied: pandas in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: matplotlib in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\tdsp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'vehicleId'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 142\u001b[0m\n\u001b[0;32m    139\u001b[0m     plot_pair_visualizations(pair_data)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 142\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[10], line 137\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/ASU Academics/Traffic Flow Theroy/MP-1/Reconstructed NGSIM I80-1 data/Data/DATA (NO MOTORCYCLES).txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    136\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m load_data(file_path)\n\u001b[1;32m--> 137\u001b[0m selected_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mfind_car_following_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m    138\u001b[0m pair_data \u001b[38;5;241m=\u001b[39m process_pair_data(raw_data, selected_pairs)\n\u001b[0;32m    139\u001b[0m plot_pair_visualizations(pair_data)\n",
            "Cell \u001b[1;32mIn[10], line 30\u001b[0m, in \u001b[0;36mfind_car_following_pairs\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfind_car_following_pairs\u001b[39m(data):\n\u001b[1;32m---> 30\u001b[0m     vehicle_groups \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvehicleId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     pairs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     32\u001b[0m     min_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m  \u001b[38;5;66;03m# 20 seconds (at 0.1s intervals)\u001b[39;00m\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\tdsp\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\tdsp\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
            "File \u001b[1;32md:\\Anaconda\\envs\\tdsp\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'vehicleId'"
          ]
        }
      ],
      "source": [
        "%pip install numpy pandas matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "\n",
        "# Configure logger\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "handler = logging.StreamHandler()\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "\n",
        "# Load and process data\n",
        "\n",
        "# Load and process data\n",
        "def load_data(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path, delimiter=' ', skip_blank_lines=True, dtype=float)\n",
        "        data.columns = ['vehicleId', 'frame', 'lane', 'position', 'speed', 'acceleration', 'vehicleLength', 'vehicleClass', 'followerId', 'leaderId']\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading data: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Helper function to find car-following pairs\n",
        "def find_car_following_pairs(data):\n",
        "    vehicle_groups = data.groupby('vehicleId')\n",
        "    pairs = []\n",
        "    min_duration = 200  # 20 seconds (at 0.1s intervals)\n",
        "\n",
        "    for vehicle_id, vehicle in vehicle_groups:\n",
        "        unique_leaders = vehicle['leaderId'].unique()\n",
        "        unique_leaders = unique_leaders[unique_leaders != -1]\n",
        "\n",
        "        for leader_id in unique_leaders:\n",
        "            start_frame = None\n",
        "            current_frame = None\n",
        "\n",
        "            for _, point in vehicle.iterrows():\n",
        "                if point['leaderId'] == leader_id:\n",
        "                    if start_frame is None:\n",
        "                        start_frame = point['frame']\n",
        "                    current_frame = point['frame']\n",
        "                elif start_frame is not None:\n",
        "                    if current_frame - start_frame >= min_duration:\n",
        "                        pairs.append({\n",
        "                            'leaderId': leader_id,\n",
        "                            'followerId': vehicle_id,\n",
        "                            'startFrame': start_frame,\n",
        "                            'endFrame': current_frame,\n",
        "                            'lane': point['lane']\n",
        "                        })\n",
        "                    start_frame = None\n",
        "\n",
        "            if start_frame is not None and current_frame - start_frame >= min_duration:\n",
        "                pairs.append({\n",
        "                    'leaderId': leader_id,\n",
        "                    'followerId': vehicle_id,\n",
        "                    'startFrame': start_frame,\n",
        "                    'endFrame': current_frame,\n",
        "                    'lane': vehicle.iloc[-1]['lane']\n",
        "                })\n",
        "\n",
        "    return pairs\n",
        "\n",
        "# Process data for selected pairs\n",
        "def process_pair_data(data, selected_pairs):\n",
        "    pair_data = []\n",
        "\n",
        "    for pair in selected_pairs:\n",
        "        pair_frames = np.arange(pair['startFrame'], pair['endFrame'] + 1)\n",
        "        leader_data = data[(data['vehicleId'] == pair['leaderId']) & (data['frame'].isin(pair_frames))]\n",
        "        follower_data = data[(data['vehicleId'] == pair['followerId']) & (data['frame'].isin(pair_frames))]\n",
        "\n",
        "        time_data = []\n",
        "        for frame in pair_frames:\n",
        "            leader_point = leader_data[leader_data['frame'] == frame].iloc[0] if not leader_data[leader_data['frame'] == frame].empty else {}\n",
        "            follower_point = follower_data[follower_data['frame'] == frame].iloc[0] if not follower_data[follower_data['frame'] == frame].empty else {}\n",
        "\n",
        "            time_data.append({\n",
        "                'time': (frame - pair['startFrame']) * 0.1,\n",
        "                'leaderSpeed': leader_point.get('speed', np.nan),\n",
        "                'followerSpeed': follower_point.get('speed', np.nan),\n",
        "                'spacing': leader_point.get('position', np.nan) - follower_point.get('position', np.nan),\n",
        "                'relativeSpeed': leader_point.get('speed', np.nan) - follower_point.get('speed', np.nan),\n",
        "                'leaderAccel': leader_point.get('acceleration', np.nan),\n",
        "                'followerAccel': follower_point.get('acceleration', np.nan)\n",
        "            })\n",
        "\n",
        "        pair_data.append({\n",
        "            'pairId': f\"{pair['leaderId']}-{pair['followerId']}\",\n",
        "            'timeData': time_data\n",
        "        })\n",
        "\n",
        "    return pair_data\n",
        "\n",
        "# Visualization functions\n",
        "def plot_pair_visualizations(pair_data):\n",
        "    for pair in pair_data:\n",
        "        time_data = pd.DataFrame(pair['timeData'])\n",
        "\n",
        "        fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
        "        fig.suptitle(f\"Car-Following Pair {pair['pairId']}\")\n",
        "\n",
        "        # Speed Profiles\n",
        "        axs[0].plot(time_data['time'], time_data['leaderSpeed'], label='Leader Speed', color='blue')\n",
        "        axs[0].plot(time_data['time'], time_data['followerSpeed'], label='Follower Speed', color='green')\n",
        "        axs[0].set_xlabel('Time (s)')\n",
        "        axs[0].set_ylabel('Speed (m/s)')\n",
        "        axs[0].legend()\n",
        "        axs[0].set_title('Speed Profiles')\n",
        "\n",
        "        # Following Distance\n",
        "        axs[1].plot(time_data['time'], time_data['spacing'], label='Space Gap', color='orange')\n",
        "        axs[1].set_xlabel('Time (s)')\n",
        "        axs[1].set_ylabel('Distance (m)')\n",
        "        axs[1].legend()\n",
        "        axs[1].set_title('Following Distance')\n",
        "\n",
        "        # Relative Speed\n",
        "        axs[2].plot(time_data['time'], time_data['relativeSpeed'], label='Relative Speed', color='red')\n",
        "        axs[2].set_xlabel('Time (s)')\n",
        "        axs[2].set_ylabel('Relative Speed (m/s)')\n",
        "        axs[2].legend()\n",
        "        axs[2].set_title('Relative Speed')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Main function to run the analysis\n",
        "def main():\n",
        "    file_path = \"D:/ASU Academics/Traffic Flow Theroy/MP-1/Reconstructed NGSIM I80-1 data/Data/DATA (NO MOTORCYCLES).txt\"\n",
        "    raw_data = load_data(file_path)\n",
        "    selected_pairs = find_car_following_pairs(raw_data)[:5]\n",
        "    pair_data = process_pair_data(raw_data, selected_pairs)\n",
        "    plot_pair_visualizations(pair_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM0v56CcdsFMwzTHD8CbcyE",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tdsp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
